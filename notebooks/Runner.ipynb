{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7fcf4e71-ef73-40cf-92bb-9a7057d2e28d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43063561-2b15-43b8-92a9-e847d53e0956",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "import yaml\n",
    "from loguru import logger\n",
    "from matplotlib import pyplot as plt\n",
    "from survos2.frontend.nb_utils import start_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4bd7cb1b-5c02-4f9e-aafb-f151234ae14b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import papermill as pm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "75b166e4-e7be-41dd-baf1-9c18e81656c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4927e322-0f5f-46de-804c-45bf813653bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/ceph/users/fot15858/SuRVoS2/tests'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5a4a75-8b35-4c6b-9d46-8b4a06bd911e",
   "metadata": {},
   "source": [
    "# Start Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "31509575-9baf-41f7-8f61-a35aed22a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "port = 8871\n",
    "loss_criterion = 'BCEDiceLoss'\n",
    "encoder_type = 'resnet50'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7af7644a-13a8-478e-b9a7-fe2563c51a9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [56738]\n",
      "INFO - Started server process [56738]  - uvicorn.server:serve:75\n",
      "INFO:     Waiting for application startup.\n",
      "INFO - Waiting for application startup.  - uvicorn.lifespan.on:startup:47\n",
      "INFO:     Application startup complete.\n",
      "INFO - Application startup complete.  - uvicorn.lifespan.on:startup:61\n",
      "INFO:     Uvicorn running on http://127.0.0.1:8871 (Press CTRL+C to quit)\n",
      "INFO - Uvicorn running on http://127.0.0.1:8871 (Press CTRL+C to quit)  - uvicorn.server:_log_started_message:207\n"
     ]
    }
   ],
   "source": [
    "#server_process = start_server(port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b63ef41-02c4-43c5-b094-1ff09d52ef93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Launcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mLauncher\u001b[49m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39mrun(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manalyzers\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcreate\u001b[39m\u001b[38;5;124m'\u001b[39m, workspace\u001b[38;5;241m=\u001b[39mworkspace_name, analyzers_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Launcher' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad8a0005-1ed8-4c11-9051-ea457ff5f6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../tests')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65484f0d-3274-445d-8f8f-26105cf1f5f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#server_process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1fc7addb-7110-41b2-8303-8db017ba4046",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1mINFO - Running notebook for: U_NET_PLUS_PLUS \u001b[0m\u001b[32m - __main__\u001b[0m:\u001b[36m<module>\u001b[0m:\u001b[36m2\u001b[0m\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60522f49d77843659067ad27803a4fe5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Executing:   0%|          | 0/47 [00:00<?, ?cell/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:     Started server process [86385]\n",
      "INFO - Started server process [86385]  - uvicorn.server:serve:75\n",
      "INFO:     Waiting for application startup.\n",
      "INFO - Waiting for application startup.  - uvicorn.lifespan.on:startup:47\n",
      "INFO:     Application startup complete.\n",
      "INFO - Application startup complete.  - uvicorn.lifespan.on:startup:61\n",
      "ERROR:    [Errno 98] error while attempting to bind on address ('127.0.0.1', 8871): address already in use\n",
      "ERROR - [Errno 98] error while attempting to bind on address ('127.0.0.1', 8871): address already in use  - uvicorn.server:startup:157\n",
      "INFO:     Waiting for application shutdown.\n",
      "INFO - Waiting for application shutdown.  - uvicorn.lifespan.on:shutdown:66\n",
      "INFO:     Application shutdown complete.\n",
      "INFO - Application shutdown complete.  - uvicorn.lifespan.on:shutdown:77\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:41204 - \"GET /workspace/set_workspace?workspace=vf_main2_sept11_roi_0_128_308_698_338_723 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:41204 - \"GET /features/existing?workspace=vf_main2_sept11_roi_0_128_308_698_338_723 HTTP/1.1\" 200 OK\n",
      "INFO:     127.0.0.1:41204 - \"GET /annotations/get_levels?workspace=vf_main2_sept11_roi_0_128_308_698_338_723 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Creating dataset on /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/default/pipelines/022_train_3d_cnn [128, 390, 385] float32 None [128, 195, 97]  - survos2.model.dataset:create:241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:     127.0.0.1:41204 - \"GET /pipelines/create?pipeline_type=train_3d_cnn&workspace=vf_main2_sept11_roi_0_128_308_698_338_723 HTTP/1.1\" 200 OK\n",
      "()\n",
      "{'anno_id': '003_level',\n",
      " 'bce_to_dice_weight': 0.7,\n",
      " 'fcn_type': 'unet3d',\n",
      " 'feature_id': '001_raw',\n",
      " 'num_augs': 1,\n",
      " 'num_epochs': 2,\n",
      " 'num_samples': 200,\n",
      " 'objects_id': '001_points',\n",
      " 'patch_overlap': [16, 16, 16],\n",
      " 'patch_size': [64, 64, 64],\n",
      " 'threshold': 0.5,\n",
      " 'workspace': 'vf_main2_sept11_roi_0_128_308_698_338_723'}\n",
      "Reading entity csv: /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/default/objects/001_points/8d00bd7311242655fe89d1c0d279f9e66a7f856fab5d196e.csv\n",
      "     Unnamed: 0    z    x    y  class_code\n",
      "0             0   29  109   17           0\n",
      "1             1   23   16  129           0\n",
      "2             2   20   33  199           0\n",
      "3             3   24  159  232           0\n",
      "4             4   35  215  159           0\n",
      "..          ...  ...  ...  ...         ...\n",
      "122         122   85  207  332           0\n",
      "123         123   85  212  338           0\n",
      "124         124   87  338    2           0\n",
      "125         125   86  366   91           0\n",
      "126         126  105  383  190           0\n",
      "\n",
      "[127 rows x 5 columns]\n",
      "False\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Making patches for 127 locations\n",
      "Making 127 bvols\n",
      "Augmented point locations (127, 4)\n",
      "Generating 127 patch volumes from image of shape (256, 518, 513)\n",
      "Generated 127 MarkedPatches of shape (127, 64, 64, 64)\n",
      "Generating 127 patch volumes from image of shape (256, 518, 513)\n",
      "Generated 127 MarkedPatches of shape (127, 64, 64, 64)\n",
      "Marked patches, unique label vols [0. 1.], img mean: 0.40730849562890015\n",
      "raw_X_train (304, 64, 64, 64), raw_X_test (77, 64, 64, 64), raw_y_train(304, 64, 64, 64), raw_y_test(77, 64, 64, 64)\n",
      "Augmented image vols shape (381, 64, 64, 64), label vols shape (381, 64, 64, 64)\n",
      "Saving image vols /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/default/annotations/003_level/vf_main2_sept11_roi_0_128_308_698_338_723_patch_vols381_img_vols_0302_1028.h5\n",
      "Saving image vols /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/default/annotations/003_level/vf_main2_sept11_roi_0_128_308_698_338_723_patch_vols381_img_labels_0302_1028.h5\n",
      "Saving image vols /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/default/annotations/003_level/vf_main2_sept11_roi_0_128_308_698_338_723_patch_vols_381_mask_gt_0302_1028.h5\n",
      "<KeysViewHDF5 ['data']>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Saving fcn model to: /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/fcn/03022023_10_28_24_trained_fcn_model  - survos2.api.pipelines:train_3d_cnn:733\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<KeysViewHDF5 ['data']>\n",
      "(381, 64, 64, 64) (381, 64, 64, 64)\n",
      "Prepared train X : (342, 64, 64, 64) and train y: (342, 64, 64, 64)  and test X: (39, 64, 64, 64) and test y (39, 64, 64, 64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Progress:   0%|          | 0/2 [00:00<?, ?it/s]\n",
      "Training:   0%|          | 0/342 [00:00<?, ?it/s]\n",
      "Training: (loss 0.1585):   0%|          | 0/342 [00:00<?, ?it/s]\n",
      "Training: (loss 0.2021):   0%|          | 0/342 [00:00<?, ?it/s]\n",
      "Training: (loss 0.2021):   1%|          | 2/342 [00:00<00:27, 12.56it/s]\n",
      "Training: (loss 0.2261):   1%|          | 2/342 [00:00<00:27, 12.56it/s]\n",
      "Training: (loss 0.1625):   1%|          | 2/342 [00:00<00:27, 12.56it/s]\n",
      "Training: (loss 0.2145):   1%|          | 2/342 [00:00<00:27, 12.56it/s]\n",
      "Training: (loss 0.2145):   1%|▏         | 5/342 [00:00<00:19, 17.65it/s]\n",
      "Training: (loss 0.1560):   1%|▏         | 5/342 [00:00<00:19, 17.65it/s]\n",
      "Training: (loss 0.1629):   1%|▏         | 5/342 [00:00<00:19, 17.65it/s]\n",
      "Training: (loss 0.1806):   1%|▏         | 5/342 [00:00<00:19, 17.65it/s]\n",
      "Training: (loss 0.1806):   2%|▏         | 8/342 [00:00<00:17, 19.01it/s]\n",
      "Training: (loss -0.0305):   2%|▏         | 8/342 [00:00<00:17, 19.01it/s]\n",
      "Training: (loss 0.0910):   2%|▏         | 8/342 [00:00<00:17, 19.01it/s] \n",
      "Training: (loss -0.0029):   2%|▏         | 8/342 [00:00<00:17, 19.01it/s]\n",
      "Training: (loss -0.0029):   3%|▎         | 11/342 [00:00<00:15, 21.58it/s]\n",
      "Training: (loss 0.0959):   3%|▎         | 11/342 [00:00<00:15, 21.58it/s] \n",
      "Training: (loss 0.0936):   3%|▎         | 11/342 [00:00<00:15, 21.58it/s]\n",
      "Training: (loss -0.0024):   3%|▎         | 11/342 [00:00<00:15, 21.58it/s]\n",
      "Training: (loss -0.0024):   4%|▍         | 14/342 [00:00<00:13, 24.06it/s]\n",
      "Training: (loss 0.1073):   4%|▍         | 14/342 [00:00<00:13, 24.06it/s] \n",
      "Training: (loss 0.7026):   4%|▍         | 14/342 [00:00<00:13, 24.06it/s]\n",
      "Training: (loss 0.1160):   4%|▍         | 14/342 [00:00<00:13, 24.06it/s]\n",
      "Training: (loss 0.1160):   5%|▍         | 17/342 [00:00<00:13, 23.61it/s]\n",
      "Training: (loss 0.0154):   5%|▍         | 17/342 [00:00<00:13, 23.61it/s]\n",
      "Training: (loss 0.5129):   5%|▍         | 17/342 [00:00<00:13, 23.61it/s]\n",
      "Training: (loss 0.2325):   5%|▍         | 17/342 [00:00<00:13, 23.61it/s]\n",
      "Training: (loss 0.2325):   6%|▌         | 20/342 [00:00<00:13, 24.19it/s]\n",
      "Training: (loss 0.0069):   6%|▌         | 20/342 [00:00<00:13, 24.19it/s]\n",
      "Training: (loss -0.0205):   6%|▌         | 20/342 [00:01<00:13, 24.19it/s]\n",
      "Training: (loss 0.0935):   6%|▌         | 20/342 [00:01<00:13, 24.19it/s] \n",
      "Training: (loss 0.0935):   7%|▋         | 23/342 [00:01<00:13, 22.87it/s]\n",
      "Training: (loss 0.1964):   7%|▋         | 23/342 [00:01<00:13, 22.87it/s]\n",
      "Training: (loss 0.7819):   7%|▋         | 23/342 [00:01<00:13, 22.87it/s]\n",
      "Training: (loss 0.0604):   7%|▋         | 23/342 [00:01<00:13, 22.87it/s]\n",
      "Training: (loss 0.0604):   8%|▊         | 26/342 [00:01<00:13, 23.48it/s]\n",
      "Training: (loss 0.5716):   8%|▊         | 26/342 [00:01<00:13, 23.48it/s]\n",
      "Training: (loss 0.0694):   8%|▊         | 26/342 [00:01<00:13, 23.48it/s]\n",
      "Training: (loss 0.0551):   8%|▊         | 26/342 [00:01<00:13, 23.48it/s]\n",
      "Training: (loss 0.0551):   8%|▊         | 29/342 [00:01<00:15, 19.83it/s]\n",
      "Training: (loss 0.0639):   8%|▊         | 29/342 [00:01<00:15, 19.83it/s]\n",
      "Training: (loss -0.0273):   8%|▊         | 29/342 [00:01<00:15, 19.83it/s]\n",
      "Training: (loss 0.1000):   8%|▊         | 29/342 [00:01<00:15, 19.83it/s] \n",
      "Training: (loss 0.1000):   9%|▉         | 32/342 [00:01<00:16, 19.21it/s]\n",
      "Training: (loss -0.0205):   9%|▉         | 32/342 [00:01<00:16, 19.21it/s]\n",
      "Training: (loss 0.0154):   9%|▉         | 32/342 [00:01<00:16, 19.21it/s] \n",
      "Training: (loss 0.0636):   9%|▉         | 32/342 [00:01<00:16, 19.21it/s]\n",
      "Training: (loss 0.0636):  10%|█         | 35/342 [00:01<00:15, 19.72it/s]\n",
      "Training: (loss 0.1070):  10%|█         | 35/342 [00:01<00:15, 19.72it/s]\n",
      "Training: (loss -0.0305):  10%|█         | 35/342 [00:01<00:15, 19.72it/s]\n",
      "Training: (loss 0.0592):  10%|█         | 35/342 [00:01<00:15, 19.72it/s] \n",
      "Training: (loss 0.0592):  11%|█         | 38/342 [00:01<00:14, 21.16it/s]\n",
      "Training: (loss 0.1999):  11%|█         | 38/342 [00:01<00:14, 21.16it/s]\n",
      "Training: (loss 0.0141):  11%|█         | 38/342 [00:01<00:14, 21.16it/s]\n",
      "Training: (loss 0.1070):  11%|█         | 38/342 [00:01<00:14, 21.16it/s]\n",
      "Training: (loss 0.1070):  12%|█▏        | 41/342 [00:01<00:13, 22.73it/s]\n",
      "Training: (loss 0.0292):  12%|█▏        | 41/342 [00:01<00:13, 22.73it/s]\n",
      "Training: (loss 0.0361):  12%|█▏        | 41/342 [00:02<00:13, 22.73it/s]\n",
      "Training: (loss -0.0226):  12%|█▏        | 41/342 [00:02<00:13, 22.73it/s]\n",
      "Training: (loss -0.0226):  13%|█▎        | 44/342 [00:02<00:13, 21.74it/s]\n",
      "Training: (loss 0.1964):  13%|█▎        | 44/342 [00:02<00:13, 21.74it/s] \n",
      "Training: (loss 0.0636):  13%|█▎        | 44/342 [00:02<00:13, 21.74it/s]\n",
      "Training: (loss 0.0929):  13%|█▎        | 44/342 [00:02<00:13, 21.74it/s]\n",
      "Training: (loss 0.0929):  14%|█▎        | 47/342 [00:02<00:13, 22.58it/s]\n",
      "Training: (loss 0.6050):  14%|█▎        | 47/342 [00:02<00:13, 22.58it/s]\n",
      "Training: (loss 0.5951):  14%|█▎        | 47/342 [00:02<00:13, 22.58it/s]\n",
      "Training: (loss 0.6050):  14%|█▎        | 47/342 [00:02<00:13, 22.58it/s]\n",
      "Training: (loss 0.6050):  15%|█▍        | 50/342 [00:02<00:13, 22.43it/s]\n",
      "Training: (loss 0.0929):  15%|█▍        | 50/342 [00:02<00:13, 22.43it/s]\n",
      "Training: (loss 0.0592):  15%|█▍        | 50/342 [00:02<00:13, 22.43it/s]\n",
      "Training: (loss 0.2325):  15%|█▍        | 50/342 [00:02<00:13, 22.43it/s]\n",
      "Training: (loss 0.2325):  15%|█▌        | 53/342 [00:02<00:16, 17.90it/s]\n",
      "Training: (loss 0.0819):  15%|█▌        | 53/342 [00:02<00:16, 17.90it/s]\n",
      "Training: (loss 0.6837):  15%|█▌        | 53/342 [00:02<00:16, 17.90it/s]\n",
      "Training: (loss -0.0089):  15%|█▌        | 53/342 [00:02<00:16, 17.90it/s]\n",
      "Training: (loss -0.0089):  16%|█▋        | 56/342 [00:02<00:17, 16.61it/s]\n",
      "Training: (loss -0.0508):  16%|█▋        | 56/342 [00:02<00:17, 16.61it/s]\n",
      "Training: (loss -0.0436):  16%|█▋        | 56/342 [00:02<00:17, 16.61it/s]\n",
      "Training: (loss 0.2871):  16%|█▋        | 56/342 [00:02<00:17, 16.61it/s] \n",
      "Training: (loss 0.2871):  17%|█▋        | 59/342 [00:02<00:14, 19.10it/s]\n",
      "Training: (loss 0.8524):  17%|█▋        | 59/342 [00:02<00:14, 19.10it/s]\n",
      "Training: (loss 0.0969):  17%|█▋        | 59/342 [00:02<00:14, 19.10it/s]\n",
      "Training: (loss 0.2889):  17%|█▋        | 59/342 [00:02<00:14, 19.10it/s]\n",
      "Training: (loss 0.0321):  17%|█▋        | 59/342 [00:03<00:14, 19.10it/s]\n",
      "Training: (loss 0.0321):  18%|█▊        | 63/342 [00:03<00:13, 21.24it/s]\n",
      "Training: (loss 0.0328):  18%|█▊        | 63/342 [00:03<00:13, 21.24it/s]\n",
      "Training: (loss 0.0328):  18%|█▊        | 63/342 [00:03<00:13, 21.24it/s]\n",
      "Training: (loss 0.0046):  18%|█▊        | 63/342 [00:03<00:13, 21.24it/s]\n",
      "Training: (loss 0.0046):  19%|█▉        | 66/342 [00:03<00:12, 22.28it/s]\n",
      "Training: (loss 0.1280):  19%|█▉        | 66/342 [00:03<00:12, 22.28it/s]\n",
      "Training: (loss 0.2871):  19%|█▉        | 66/342 [00:03<00:12, 22.28it/s]\n",
      "Training: (loss 0.2405):  19%|█▉        | 66/342 [00:03<00:12, 22.28it/s]\n",
      "Training: (loss 0.3022):  19%|█▉        | 66/342 [00:03<00:12, 22.28it/s]\n",
      "Training: (loss 0.3022):  20%|██        | 70/342 [00:03<00:11, 23.40it/s]\n",
      "Training: (loss 0.1964):  20%|██        | 70/342 [00:03<00:11, 23.40it/s]\n",
      "Training: (loss -0.0520):  20%|██        | 70/342 [00:03<00:11, 23.40it/s]\n",
      "Training: (loss 0.3638):  20%|██        | 70/342 [00:03<00:11, 23.40it/s] \n",
      "Training: (loss 0.3638):  21%|██▏       | 73/342 [00:03<00:11, 24.12it/s]\n",
      "Training: (loss 0.0846):  21%|██▏       | 73/342 [00:03<00:11, 24.12it/s]\n",
      "Training: (loss 0.4200):  21%|██▏       | 73/342 [00:03<00:11, 24.12it/s]\n",
      "Training: (loss 0.1777):  21%|██▏       | 73/342 [00:03<00:11, 24.12it/s]\n",
      "Training: (loss 0.1777):  22%|██▏       | 76/342 [00:03<00:10, 25.28it/s]\n",
      "Training: (loss 0.3166):  22%|██▏       | 76/342 [00:03<00:10, 25.28it/s]\n",
      "Training: (loss 0.0820):  22%|██▏       | 76/342 [00:03<00:10, 25.28it/s]\n",
      "Training: (loss 0.0587):  22%|██▏       | 76/342 [00:03<00:10, 25.28it/s]\n",
      "Training: (loss 0.0587):  23%|██▎       | 79/342 [00:03<00:10, 25.54it/s]\n",
      "Training: (loss 0.0101):  23%|██▎       | 79/342 [00:03<00:10, 25.54it/s]\n",
      "Training: (loss 0.3166):  23%|██▎       | 79/342 [00:03<00:10, 25.54it/s]\n",
      "Training: (loss 0.0233):  23%|██▎       | 79/342 [00:03<00:10, 25.54it/s]\n",
      "Training: (loss 0.0233):  24%|██▍       | 82/342 [00:03<00:10, 25.17it/s]\n",
      "Training: (loss 0.0935):  24%|██▍       | 82/342 [00:03<00:10, 25.17it/s]\n",
      "Training: (loss 0.2079):  24%|██▍       | 82/342 [00:03<00:10, 25.17it/s]\n",
      "Training: (loss 0.0604):  24%|██▍       | 82/342 [00:03<00:10, 25.17it/s]\n",
      "Training: (loss 0.0604):  25%|██▍       | 85/342 [00:03<00:09, 26.01it/s]\n",
      "Training: (loss 0.0883):  25%|██▍       | 85/342 [00:03<00:09, 26.01it/s]\n",
      "Training: (loss 0.0011):  25%|██▍       | 85/342 [00:03<00:09, 26.01it/s]\n",
      "Training: (loss -0.0029):  25%|██▍       | 85/342 [00:04<00:09, 26.01it/s]\n",
      "Training: (loss -0.0029):  26%|██▌       | 88/342 [00:04<00:10, 23.45it/s]\n",
      "Training: (loss 0.0463):  26%|██▌       | 88/342 [00:04<00:10, 23.45it/s] \n",
      "Training: (loss -0.0286):  26%|██▌       | 88/342 [00:04<00:10, 23.45it/s]\n",
      "Training: (loss 0.0959):  26%|██▌       | 88/342 [00:04<00:10, 23.45it/s] \n",
      "Training: (loss 0.0959):  27%|██▋       | 91/342 [00:04<00:14, 16.79it/s]\n",
      "Training: (loss 0.2405):  27%|██▋       | 91/342 [00:04<00:14, 16.79it/s]\n",
      "Training: (loss 0.0141):  27%|██▋       | 91/342 [00:04<00:14, 16.79it/s]\n",
      "Training: (loss 0.1455):  27%|██▋       | 91/342 [00:04<00:14, 16.79it/s]\n",
      "Training: (loss 0.1455):  27%|██▋       | 94/342 [00:04<00:14, 17.58it/s]\n",
      "Training: (loss -0.0032):  27%|██▋       | 94/342 [00:04<00:14, 17.58it/s]\n",
      "Training: (loss 0.0304):  27%|██▋       | 94/342 [00:04<00:14, 17.58it/s] \n",
      "Training: (loss 0.0304):  28%|██▊       | 96/342 [00:04<00:13, 17.98it/s]\n",
      "Training: (loss 0.0101):  28%|██▊       | 96/342 [00:04<00:13, 17.98it/s]\n",
      "Training: (loss 0.0431):  28%|██▊       | 96/342 [00:04<00:13, 17.98it/s]\n",
      "Training: (loss 0.0431):  29%|██▊       | 98/342 [00:04<00:14, 16.60it/s]\n",
      "Training: (loss 0.8518):  29%|██▊       | 98/342 [00:04<00:14, 16.60it/s]\n",
      "Training: (loss 0.0819):  29%|██▊       | 98/342 [00:04<00:14, 16.60it/s]\n",
      "Training: (loss 0.0819):  29%|██▉       | 100/342 [00:04<00:14, 16.41it/s]\n",
      "Training: (loss 0.1071):  29%|██▉       | 100/342 [00:04<00:14, 16.41it/s]\n",
      "Training: (loss 0.1216):  29%|██▉       | 100/342 [00:05<00:14, 16.41it/s]\n",
      "Training: (loss 0.1216):  30%|██▉       | 102/342 [00:05<00:16, 14.32it/s]\n",
      "Training: (loss 0.0389):  30%|██▉       | 102/342 [00:05<00:16, 14.32it/s]\n",
      "Training: (loss 0.5326):  30%|██▉       | 102/342 [00:05<00:16, 14.32it/s]\n",
      "Training: (loss 0.5326):  30%|███       | 104/342 [00:05<00:16, 14.61it/s]\n",
      "Training: (loss 0.2889):  30%|███       | 104/342 [00:05<00:16, 14.61it/s]\n",
      "Training: (loss 0.2383):  30%|███       | 104/342 [00:05<00:16, 14.61it/s]\n",
      "Training: (loss 0.2383):  31%|███       | 106/342 [00:05<00:14, 15.74it/s]\n",
      "Training: (loss 0.2106):  31%|███       | 106/342 [00:05<00:14, 15.74it/s]\n",
      "Training: (loss 0.1035):  31%|███       | 106/342 [00:05<00:14, 15.74it/s]\n",
      "Training: (loss -0.0019):  31%|███       | 106/342 [00:05<00:14, 15.74it/s]\n",
      "Training: (loss -0.0019):  32%|███▏      | 109/342 [00:05<00:13, 17.63it/s]\n",
      "Training: (loss 0.0450):  32%|███▏      | 109/342 [00:05<00:13, 17.63it/s] \n",
      "Training: (loss 0.3638):  32%|███▏      | 109/342 [00:05<00:13, 17.63it/s]\n",
      "Training: (loss 0.0450):  32%|███▏      | 109/342 [00:05<00:13, 17.63it/s]\n",
      "Training: (loss 0.0450):  33%|███▎      | 112/342 [00:05<00:11, 20.06it/s]\n",
      "Training: (loss 0.0912):  33%|███▎      | 112/342 [00:05<00:11, 20.06it/s]\n",
      "Training: (loss 0.0440):  33%|███▎      | 112/342 [00:05<00:11, 20.06it/s]\n",
      "Training: (loss 0.0630):  33%|███▎      | 112/342 [00:05<00:11, 20.06it/s]\n",
      "Training: (loss 0.0147):  33%|███▎      | 112/342 [00:05<00:11, 20.06it/s]\n",
      "Training: (loss 0.0147):  34%|███▍      | 116/342 [00:05<00:09, 23.68it/s]\n",
      "Training: (loss -0.0205):  34%|███▍      | 116/342 [00:05<00:09, 23.68it/s]\n",
      "Training: (loss 0.0254):  34%|███▍      | 116/342 [00:05<00:09, 23.68it/s] \n",
      "Training: (loss 0.1881):  34%|███▍      | 116/342 [00:05<00:09, 23.68it/s]\n",
      "Training: (loss 0.1881):  35%|███▍      | 119/342 [00:05<00:09, 24.76it/s]\n",
      "Training: (loss 0.3638):  35%|███▍      | 119/342 [00:05<00:09, 24.76it/s]\n",
      "Training: (loss 0.0101):  35%|███▍      | 119/342 [00:05<00:09, 24.76it/s]\n",
      "Training: (loss 0.2983):  35%|███▍      | 119/342 [00:05<00:09, 24.76it/s]\n",
      "Training: (loss 0.2983):  36%|███▌      | 122/342 [00:05<00:08, 25.16it/s]\n",
      "Training: (loss 0.0791):  36%|███▌      | 122/342 [00:05<00:08, 25.16it/s]\n",
      "Training: (loss 0.1071):  36%|███▌      | 122/342 [00:05<00:08, 25.16it/s]\n",
      "Training: (loss 0.5326):  36%|███▌      | 122/342 [00:05<00:08, 25.16it/s]\n",
      "Training: (loss 0.5326):  37%|███▋      | 125/342 [00:05<00:08, 25.96it/s]\n",
      "Training: (loss -0.0089):  37%|███▋      | 125/342 [00:06<00:08, 25.96it/s]\n",
      "Training: (loss 0.0292):  37%|███▋      | 125/342 [00:06<00:08, 25.96it/s] \n",
      "Training: (loss 0.1035):  37%|███▋      | 125/342 [00:06<00:08, 25.96it/s]\n",
      "Training: (loss 0.1035):  37%|███▋      | 128/342 [00:06<00:08, 25.00it/s]\n",
      "Training: (loss 0.0630):  37%|███▋      | 128/342 [00:06<00:08, 25.00it/s]\n",
      "Training: (loss 0.0304):  37%|███▋      | 128/342 [00:06<00:08, 25.00it/s]\n",
      "Training: (loss 0.2985):  37%|███▋      | 128/342 [00:06<00:08, 25.00it/s]\n",
      "Training: (loss 0.0587):  37%|███▋      | 128/342 [00:06<00:08, 25.00it/s]\n",
      "Training: (loss 0.0587):  39%|███▊      | 132/342 [00:06<00:08, 25.63it/s]\n",
      "Training: (loss -0.0089):  39%|███▊      | 132/342 [00:06<00:08, 25.63it/s]\n",
      "Training: (loss 0.1124):  39%|███▊      | 132/342 [00:06<00:08, 25.63it/s] \n",
      "Training: (loss 0.0348):  39%|███▊      | 132/342 [00:06<00:08, 25.63it/s]\n",
      "Training: (loss 0.0348):  39%|███▉      | 135/342 [00:06<00:07, 26.25it/s]\n",
      "Training: (loss 0.1121):  39%|███▉      | 135/342 [00:06<00:07, 26.25it/s]\n",
      "Training: (loss 0.0034):  39%|███▉      | 135/342 [00:06<00:07, 26.25it/s]\n",
      "Training: (loss -0.0520):  39%|███▉      | 135/342 [00:06<00:07, 26.25it/s]\n",
      "Training: (loss -0.0520):  40%|████      | 138/342 [00:06<00:07, 26.02it/s]\n",
      "Training: (loss 0.0910):  40%|████      | 138/342 [00:06<00:07, 26.02it/s] \n",
      "Training: (loss 0.0132):  40%|████      | 138/342 [00:06<00:07, 26.02it/s]\n",
      "Training: (loss 0.0712):  40%|████      | 138/342 [00:06<00:07, 26.02it/s]\n",
      "Training: (loss 0.0712):  41%|████      | 141/342 [00:06<00:09, 21.92it/s]\n",
      "Training: (loss 0.7026):  41%|████      | 141/342 [00:06<00:09, 21.92it/s]\n",
      "Training: (loss 0.1071):  41%|████      | 141/342 [00:06<00:09, 21.92it/s]\n",
      "Training: (loss 0.0592):  41%|████      | 141/342 [00:06<00:09, 21.92it/s]\n",
      "Training: (loss 0.0592):  42%|████▏     | 144/342 [00:06<00:08, 23.69it/s]\n",
      "Training: (loss 0.5679):  42%|████▏     | 144/342 [00:06<00:08, 23.69it/s]\n",
      "Training: (loss -0.0436):  42%|████▏     | 144/342 [00:06<00:08, 23.69it/s]\n",
      "Training: (loss 0.1881):  42%|████▏     | 144/342 [00:06<00:08, 23.69it/s] \n",
      "Training: (loss 0.1881):  43%|████▎     | 147/342 [00:06<00:09, 21.40it/s]\n",
      "Training: (loss 0.0321):  43%|████▎     | 147/342 [00:06<00:09, 21.40it/s]\n",
      "Training: (loss 0.5909):  43%|████▎     | 147/342 [00:07<00:09, 21.40it/s]\n",
      "Training: (loss 0.0116):  43%|████▎     | 147/342 [00:07<00:09, 21.40it/s]\n",
      "Training: (loss 0.0361):  43%|████▎     | 147/342 [00:07<00:09, 21.40it/s]\n",
      "Training: (loss 0.0361):  44%|████▍     | 151/342 [00:07<00:07, 24.11it/s]\n",
      "Training: (loss 0.0869):  44%|████▍     | 151/342 [00:07<00:07, 24.11it/s]\n",
      "Training: (loss 0.0147):  44%|████▍     | 151/342 [00:07<00:07, 24.11it/s]\n",
      "Training: (loss 0.0712):  44%|████▍     | 151/342 [00:07<00:07, 24.11it/s]\n",
      "Training: (loss 0.0712):  45%|████▌     | 154/342 [00:07<00:08, 23.14it/s]\n",
      "Training: (loss 0.3202):  45%|████▌     | 154/342 [00:07<00:08, 23.14it/s]\n",
      "Training: (loss 0.3567):  45%|████▌     | 154/342 [00:07<00:08, 23.14it/s]\n",
      "Training: (loss 0.1431):  45%|████▌     | 154/342 [00:07<00:08, 23.14it/s]\n",
      "Training: (loss 0.1431):  46%|████▌     | 157/342 [00:07<00:07, 23.63it/s]\n",
      "Training: (loss 0.0321):  46%|████▌     | 157/342 [00:07<00:07, 23.63it/s]\n",
      "Training: (loss 0.3567):  46%|████▌     | 157/342 [00:07<00:07, 23.63it/s]\n",
      "Training: (loss 0.1121):  46%|████▌     | 157/342 [00:07<00:07, 23.63it/s]\n",
      "Training: (loss 0.1121):  47%|████▋     | 160/342 [00:07<00:09, 19.22it/s]\n",
      "Training: (loss 0.0702):  47%|████▋     | 160/342 [00:07<00:09, 19.22it/s]\n",
      "Training: (loss 0.0009):  47%|████▋     | 160/342 [00:07<00:09, 19.22it/s]\n",
      "Training: (loss 0.4200):  47%|████▋     | 160/342 [00:07<00:09, 19.22it/s]\n",
      "Training: (loss 0.4200):  48%|████▊     | 163/342 [00:07<00:09, 19.78it/s]\n",
      "Training: (loss -0.0273):  48%|████▊     | 163/342 [00:07<00:09, 19.78it/s]\n",
      "Training: (loss 0.5129):  48%|████▊     | 163/342 [00:07<00:09, 19.78it/s] \n",
      "Training: (loss -0.0323):  48%|████▊     | 163/342 [00:07<00:09, 19.78it/s]\n",
      "Training: (loss -0.0323):  49%|████▊     | 166/342 [00:07<00:08, 21.77it/s]\n",
      "Training: (loss -0.0305):  49%|████▊     | 166/342 [00:07<00:08, 21.77it/s]\n",
      "Training: (loss 0.0463):  49%|████▊     | 166/342 [00:07<00:08, 21.77it/s] \n",
      "Training: (loss -0.0508):  49%|████▊     | 166/342 [00:07<00:08, 21.77it/s]\n",
      "Training: (loss -0.0508):  49%|████▉     | 169/342 [00:07<00:07, 22.83it/s]\n",
      "Training: (loss 0.0389):  49%|████▉     | 169/342 [00:07<00:07, 22.83it/s] \n",
      "Training: (loss 0.2325):  49%|████▉     | 169/342 [00:08<00:07, 22.83it/s]\n",
      "Training: (loss 0.0009):  49%|████▉     | 169/342 [00:08<00:07, 22.83it/s]\n",
      "Training: (loss 0.0009):  50%|█████     | 172/342 [00:08<00:07, 21.48it/s]\n",
      "Training: (loss 0.5951):  50%|█████     | 172/342 [00:08<00:07, 21.48it/s]\n",
      "Training: (loss 0.1881):  50%|█████     | 172/342 [00:08<00:07, 21.48it/s]\n",
      "Training: (loss 0.7133):  50%|█████     | 172/342 [00:08<00:07, 21.48it/s]\n",
      "Training: (loss 0.7133):  51%|█████     | 175/342 [00:08<00:07, 23.42it/s]\n",
      "Training: (loss 0.2871):  51%|█████     | 175/342 [00:08<00:07, 23.42it/s]\n",
      "Training: (loss 0.0702):  51%|█████     | 175/342 [00:08<00:07, 23.42it/s]\n",
      "Training: (loss 0.0011):  51%|█████     | 175/342 [00:08<00:07, 23.42it/s]\n",
      "Training: (loss 0.0011):  52%|█████▏    | 178/342 [00:08<00:07, 21.85it/s]\n",
      "Training: (loss 0.1124):  52%|█████▏    | 178/342 [00:08<00:07, 21.85it/s]\n",
      "Training: (loss 0.1000):  52%|█████▏    | 178/342 [00:08<00:07, 21.85it/s]\n",
      "Training: (loss 0.0361):  52%|█████▏    | 178/342 [00:08<00:07, 21.85it/s]\n",
      "Training: (loss 0.0361):  53%|█████▎    | 181/342 [00:08<00:06, 23.23it/s]\n",
      "Training: (loss 0.1216):  53%|█████▎    | 181/342 [00:08<00:06, 23.23it/s]\n",
      "Training: (loss 0.0173):  53%|█████▎    | 181/342 [00:08<00:06, 23.23it/s]\n",
      "Training: (loss 0.0233):  53%|█████▎    | 181/342 [00:08<00:06, 23.23it/s]\n",
      "Training: (loss 0.0233):  54%|█████▍    | 184/342 [00:08<00:06, 24.13it/s]\n",
      "Training: (loss 0.0011):  54%|█████▍    | 184/342 [00:08<00:06, 24.13it/s]\n",
      "Training: (loss 0.1035):  54%|█████▍    | 184/342 [00:08<00:06, 24.13it/s]\n",
      "Training: (loss 0.0604):  54%|█████▍    | 184/342 [00:08<00:06, 24.13it/s]\n",
      "Training: (loss 0.0910):  54%|█████▍    | 184/342 [00:08<00:06, 24.13it/s]\n",
      "Training: (loss 0.0910):  55%|█████▍    | 188/342 [00:08<00:05, 25.93it/s]\n",
      "Training: (loss 0.2079):  55%|█████▍    | 188/342 [00:08<00:05, 25.93it/s]\n",
      "Training: (loss 0.0846):  55%|█████▍    | 188/342 [00:08<00:05, 25.93it/s]\n",
      "Training: (loss 0.0254):  55%|█████▍    | 188/342 [00:08<00:05, 25.93it/s]\n",
      "Training: (loss 0.4771):  55%|█████▍    | 188/342 [00:08<00:05, 25.93it/s]\n",
      "Training: (loss 0.4771):  56%|█████▌    | 192/342 [00:08<00:05, 27.01it/s]\n",
      "Training: (loss 0.4771):  56%|█████▌    | 192/342 [00:08<00:05, 27.01it/s]\n",
      "Training: (loss 0.2124):  56%|█████▌    | 192/342 [00:08<00:05, 27.01it/s]\n",
      "Training: (loss 0.0791):  56%|█████▌    | 192/342 [00:08<00:05, 27.01it/s]\n",
      "Training: (loss 0.0791):  57%|█████▋    | 195/342 [00:08<00:05, 26.57it/s]\n",
      "Training: (loss 0.2124):  57%|█████▋    | 195/342 [00:09<00:05, 26.57it/s]\n",
      "Training: (loss 0.5212):  57%|█████▋    | 195/342 [00:09<00:05, 26.57it/s]\n",
      "Training: (loss 0.8524):  57%|█████▋    | 195/342 [00:09<00:05, 26.57it/s]\n",
      "Training: (loss 0.8524):  58%|█████▊    | 198/342 [00:09<00:05, 26.28it/s]\n",
      "Training: (loss 0.5496):  58%|█████▊    | 198/342 [00:09<00:05, 26.28it/s]\n",
      "Training: (loss 0.0791):  58%|█████▊    | 198/342 [00:09<00:05, 26.28it/s]\n",
      "Training: (loss 0.0630):  58%|█████▊    | 198/342 [00:09<00:05, 26.28it/s]\n",
      "Training: (loss 0.0630):  59%|█████▉    | 201/342 [00:09<00:05, 26.51it/s]\n",
      "Training: (loss 0.5679):  59%|█████▉    | 201/342 [00:09<00:05, 26.51it/s]\n",
      "Training: (loss 0.5467):  59%|█████▉    | 201/342 [00:09<00:05, 26.51it/s]\n",
      "Training: (loss -0.0024):  59%|█████▉    | 201/342 [00:09<00:05, 26.51it/s]\n",
      "Training: (loss -0.0024):  60%|█████▉    | 204/342 [00:09<00:05, 25.80it/s]\n",
      "Training: (loss 0.2405):  60%|█████▉    | 204/342 [00:09<00:05, 25.80it/s] \n",
      "Training: (loss 0.0846):  60%|█████▉    | 204/342 [00:09<00:05, 25.80it/s]\n",
      "Training: (loss 0.0935):  60%|█████▉    | 204/342 [00:09<00:05, 25.80it/s]\n",
      "Training: (loss 0.0935):  61%|██████    | 207/342 [00:09<00:05, 24.88it/s]\n",
      "Training: (loss 0.0636):  61%|██████    | 207/342 [00:09<00:05, 24.88it/s]\n",
      "Training: (loss 0.2889):  61%|██████    | 207/342 [00:09<00:05, 24.88it/s]\n",
      "Training: (loss 0.1999):  61%|██████    | 207/342 [00:09<00:05, 24.88it/s]\n",
      "Training: (loss 0.1999):  61%|██████▏   | 210/342 [00:09<00:05, 25.32it/s]\n",
      "Training: (loss 0.0254):  61%|██████▏   | 210/342 [00:09<00:05, 25.32it/s]\n",
      "Training: (loss 0.1777):  61%|██████▏   | 210/342 [00:09<00:05, 25.32it/s]\n",
      "Training: (loss 0.3567):  61%|██████▏   | 210/342 [00:09<00:05, 25.32it/s]\n",
      "Training: (loss 0.3567):  62%|██████▏   | 213/342 [00:09<00:05, 25.48it/s]\n",
      "Training: (loss 0.5326):  62%|██████▏   | 213/342 [00:09<00:05, 25.48it/s]\n",
      "Training: (loss 0.0869):  62%|██████▏   | 213/342 [00:09<00:05, 25.48it/s]\n",
      "Training: (loss -0.0115):  62%|██████▏   | 213/342 [00:09<00:05, 25.48it/s]\n",
      "Training: (loss -0.0115):  63%|██████▎   | 216/342 [00:09<00:04, 26.59it/s]\n",
      "Training: (loss 0.0116):  63%|██████▎   | 216/342 [00:09<00:04, 26.59it/s] \n",
      "Training: (loss 0.1280):  63%|██████▎   | 216/342 [00:09<00:04, 26.59it/s]\n",
      "Training: (loss 0.5212):  63%|██████▎   | 216/342 [00:09<00:04, 26.59it/s]\n",
      "Training: (loss 0.5212):  64%|██████▍   | 219/342 [00:09<00:04, 27.30it/s]\n",
      "Training: (loss 0.0168):  64%|██████▍   | 219/342 [00:09<00:04, 27.30it/s]\n",
      "Training: (loss 0.0141):  64%|██████▍   | 219/342 [00:09<00:04, 27.30it/s]\n",
      "Training: (loss 0.3022):  64%|██████▍   | 219/342 [00:09<00:04, 27.30it/s]\n",
      "Training: (loss 0.3022):  65%|██████▍   | 222/342 [00:09<00:04, 26.69it/s]\n",
      "Training: (loss -0.0019):  65%|██████▍   | 222/342 [00:10<00:04, 26.69it/s]\n",
      "Training: (loss 0.1121):  65%|██████▍   | 222/342 [00:10<00:04, 26.69it/s] \n",
      "Training: (loss 0.2106):  65%|██████▍   | 222/342 [00:10<00:04, 26.69it/s]\n",
      "Training: (loss 0.2106):  66%|██████▌   | 225/342 [00:10<00:04, 25.79it/s]\n",
      "Training: (loss 0.8524):  66%|██████▌   | 225/342 [00:10<00:04, 25.79it/s]\n",
      "Training: (loss 0.3166):  66%|██████▌   | 225/342 [00:10<00:04, 25.79it/s]\n",
      "Training: (loss 0.2383):  66%|██████▌   | 225/342 [00:10<00:04, 25.79it/s]\n",
      "Training: (loss 0.2383):  67%|██████▋   | 228/342 [00:10<00:04, 26.68it/s]\n",
      "Training: (loss 0.6212):  67%|██████▋   | 228/342 [00:10<00:04, 26.68it/s]\n",
      "Training: (loss 0.8518):  67%|██████▋   | 228/342 [00:10<00:04, 26.68it/s]\n",
      "Training: (loss 0.0034):  67%|██████▋   | 228/342 [00:10<00:04, 26.68it/s]\n",
      "Training: (loss 0.0034):  68%|██████▊   | 231/342 [00:10<00:04, 26.15it/s]\n",
      "Training: (loss 0.5108):  68%|██████▊   | 231/342 [00:10<00:04, 26.15it/s]\n",
      "Training: (loss 0.7133):  68%|██████▊   | 231/342 [00:10<00:04, 26.15it/s]\n",
      "Training: (loss 0.5496):  68%|██████▊   | 231/342 [00:10<00:04, 26.15it/s]\n",
      "Training: (loss 0.5496):  68%|██████▊   | 234/342 [00:10<00:04, 22.79it/s]\n",
      "Training: (loss 0.1455):  68%|██████▊   | 234/342 [00:10<00:04, 22.79it/s]\n",
      "Training: (loss 0.0173):  68%|██████▊   | 234/342 [00:10<00:04, 22.79it/s]\n",
      "Training: (loss 0.1514):  68%|██████▊   | 234/342 [00:10<00:04, 22.79it/s]\n",
      "Training: (loss 0.1514):  69%|██████▉   | 237/342 [00:10<00:05, 20.35it/s]\n",
      "Training: (loss 0.0857):  69%|██████▉   | 237/342 [00:10<00:05, 20.35it/s]\n",
      "Training: (loss 0.1073):  69%|██████▉   | 237/342 [00:10<00:05, 20.35it/s]\n",
      "Training: (loss 0.0043):  69%|██████▉   | 237/342 [00:10<00:05, 20.35it/s]\n",
      "Training: (loss 0.0043):  70%|███████   | 240/342 [00:10<00:05, 20.10it/s]\n",
      "Training: (loss 0.0233):  70%|███████   | 240/342 [00:10<00:05, 20.10it/s]\n",
      "Training: (loss 0.2985):  70%|███████   | 240/342 [00:10<00:05, 20.10it/s]\n",
      "Training: (loss -0.0115):  70%|███████   | 240/342 [00:10<00:05, 20.10it/s]\n",
      "Training: (loss 0.1431):  70%|███████   | 240/342 [00:10<00:05, 20.10it/s] \n",
      "Training: (loss 0.1431):  71%|███████▏  | 244/342 [00:10<00:04, 23.20it/s]\n",
      "Training: (loss 0.5467):  71%|███████▏  | 244/342 [00:11<00:04, 23.20it/s]\n",
      "Training: (loss 0.2983):  71%|███████▏  | 244/342 [00:11<00:04, 23.20it/s]\n",
      "Training: (loss 0.2079):  71%|███████▏  | 244/342 [00:11<00:04, 23.20it/s]\n",
      "Training: (loss 0.2079):  72%|███████▏  | 247/342 [00:11<00:04, 21.42it/s]\n",
      "Training: (loss 0.1455):  72%|███████▏  | 247/342 [00:11<00:04, 21.42it/s]\n",
      "Training: (loss 0.6050):  72%|███████▏  | 247/342 [00:11<00:04, 21.42it/s]\n",
      "Training: (loss 0.0440):  72%|███████▏  | 247/342 [00:11<00:04, 21.42it/s]\n",
      "Training: (loss 0.0440):  73%|███████▎  | 250/342 [00:11<00:04, 21.43it/s]\n",
      "Training: (loss 0.1214):  73%|███████▎  | 250/342 [00:11<00:04, 21.43it/s]\n",
      "Training: (loss -0.0273):  73%|███████▎  | 250/342 [00:11<00:04, 21.43it/s]\n",
      "Training: (loss 0.0857):  73%|███████▎  | 250/342 [00:11<00:04, 21.43it/s] \n",
      "Training: (loss 0.0857):  74%|███████▍  | 253/342 [00:11<00:04, 19.40it/s]\n",
      "Training: (loss 0.1121):  74%|███████▍  | 253/342 [00:11<00:04, 19.40it/s]\n",
      "Training: (loss 0.8518):  74%|███████▍  | 253/342 [00:11<00:04, 19.40it/s]\n",
      "Training: (loss 0.0440):  74%|███████▍  | 253/342 [00:11<00:04, 19.40it/s]\n",
      "Training: (loss 0.0440):  75%|███████▍  | 256/342 [00:11<00:04, 20.22it/s]\n",
      "Training: (loss 0.1121):  75%|███████▍  | 256/342 [00:11<00:04, 20.22it/s]\n",
      "Training: (loss 0.7026):  75%|███████▍  | 256/342 [00:11<00:04, 20.22it/s]\n",
      "Training: (loss 0.0450):  75%|███████▍  | 256/342 [00:11<00:04, 20.22it/s]\n",
      "Training: (loss 0.0450):  76%|███████▌  | 259/342 [00:11<00:03, 21.27it/s]\n",
      "Training: (loss 0.5129):  76%|███████▌  | 259/342 [00:11<00:03, 21.27it/s]\n",
      "Training: (loss 0.0820):  76%|███████▌  | 259/342 [00:11<00:03, 21.27it/s]\n",
      "Training: (loss 0.5108):  76%|███████▌  | 259/342 [00:11<00:03, 21.27it/s]\n",
      "Training: (loss 0.5108):  77%|███████▋  | 262/342 [00:11<00:04, 18.28it/s]\n",
      "Training: (loss 0.0908):  77%|███████▋  | 262/342 [00:11<00:04, 18.28it/s]\n",
      "Training: (loss 0.0936):  77%|███████▋  | 262/342 [00:12<00:04, 18.28it/s]\n",
      "Training: (loss 0.0431):  77%|███████▋  | 262/342 [00:12<00:04, 18.28it/s]\n",
      "Training: (loss 0.0431):  77%|███████▋  | 265/342 [00:12<00:03, 20.33it/s]\n",
      "Training: (loss 0.0857):  77%|███████▋  | 265/342 [00:12<00:03, 20.33it/s]\n",
      "Training: (loss 0.6837):  77%|███████▋  | 265/342 [00:12<00:03, 20.33it/s]\n",
      "Training: (loss -0.0436):  77%|███████▋  | 265/342 [00:12<00:03, 20.33it/s]\n",
      "Training: (loss 0.0599):  77%|███████▋  | 265/342 [00:12<00:03, 20.33it/s] \n",
      "Training: (loss 0.0599):  79%|███████▊  | 269/342 [00:12<00:03, 22.41it/s]\n",
      "Training: (loss 0.0599):  79%|███████▊  | 269/342 [00:12<00:03, 22.41it/s]\n",
      "Training: (loss 0.1124):  79%|███████▊  | 269/342 [00:12<00:03, 22.41it/s]\n",
      "Training: (loss 0.0046):  79%|███████▊  | 269/342 [00:12<00:03, 22.41it/s]\n",
      "Training: (loss 0.0046):  80%|███████▉  | 272/342 [00:12<00:03, 21.06it/s]\n",
      "Training: (loss 0.1216):  80%|███████▉  | 272/342 [00:12<00:03, 21.06it/s]\n",
      "Training: (loss 0.5951):  80%|███████▉  | 272/342 [00:12<00:03, 21.06it/s]\n",
      "Training: (loss 0.0034):  80%|███████▉  | 272/342 [00:12<00:03, 21.06it/s]\n",
      "Training: (loss 0.0034):  80%|████████  | 275/342 [00:12<00:03, 18.82it/s]\n",
      "Training: (loss 0.0912):  80%|████████  | 275/342 [00:12<00:03, 18.82it/s]\n",
      "Training: (loss 0.1127):  80%|████████  | 275/342 [00:12<00:03, 18.82it/s]\n",
      "Training: (loss 0.1008):  80%|████████  | 275/342 [00:12<00:03, 18.82it/s]\n",
      "Training: (loss 0.1008):  81%|████████▏ | 278/342 [00:12<00:03, 19.50it/s]\n",
      "Training: (loss 0.1000):  81%|████████▏ | 278/342 [00:12<00:03, 19.50it/s]\n",
      "Training: (loss 0.1276):  81%|████████▏ | 278/342 [00:12<00:03, 19.50it/s]\n",
      "Training: (loss 0.0694):  81%|████████▏ | 278/342 [00:12<00:03, 19.50it/s]\n",
      "Training: (loss 0.0694):  82%|████████▏ | 281/342 [00:12<00:03, 19.59it/s]\n",
      "Training: (loss 0.1008):  82%|████████▏ | 281/342 [00:12<00:03, 19.59it/s]\n",
      "Training: (loss 0.4877):  82%|████████▏ | 281/342 [00:12<00:03, 19.59it/s]\n",
      "Training: (loss 0.0348):  82%|████████▏ | 281/342 [00:12<00:03, 19.59it/s]\n",
      "Training: (loss 0.0348):  83%|████████▎ | 284/342 [00:12<00:02, 20.35it/s]\n",
      "Training: (loss 0.1160):  83%|████████▎ | 284/342 [00:13<00:02, 20.35it/s]\n",
      "Training: (loss 0.2983):  83%|████████▎ | 284/342 [00:13<00:02, 20.35it/s]\n",
      "Training: (loss 0.0969):  83%|████████▎ | 284/342 [00:13<00:02, 20.35it/s]\n",
      "Training: (loss 0.0969):  84%|████████▍ | 287/342 [00:13<00:02, 21.05it/s]\n",
      "Training: (loss 0.1214):  84%|████████▍ | 287/342 [00:13<00:02, 21.05it/s]\n",
      "Training: (loss -0.0024):  84%|████████▍ | 287/342 [00:13<00:02, 21.05it/s]\n",
      "Training: (loss 0.1777):  84%|████████▍ | 287/342 [00:13<00:02, 21.05it/s] \n",
      "Training: (loss 0.1777):  85%|████████▍ | 290/342 [00:13<00:02, 19.87it/s]\n",
      "Training: (loss 0.0043):  85%|████████▍ | 290/342 [00:13<00:02, 19.87it/s]\n",
      "Training: (loss 0.0869):  85%|████████▍ | 290/342 [00:13<00:02, 19.87it/s]\n",
      "Training: (loss -0.0520):  85%|████████▍ | 290/342 [00:13<00:02, 19.87it/s]\n",
      "Training: (loss -0.0520):  86%|████████▌ | 293/342 [00:13<00:02, 18.20it/s]\n",
      "Training: (loss 0.0694):  86%|████████▌ | 293/342 [00:13<00:02, 18.20it/s] \n",
      "Training: (loss 0.0348):  86%|████████▌ | 293/342 [00:13<00:02, 18.20it/s]\n",
      "Training: (loss 0.0348):  86%|████████▋ | 295/342 [00:13<00:02, 17.27it/s]\n",
      "Training: (loss 0.2985):  86%|████████▋ | 295/342 [00:13<00:02, 17.27it/s]\n",
      "Training: (loss 0.7819):  86%|████████▋ | 295/342 [00:13<00:02, 17.27it/s]\n",
      "Training: (loss 0.0599):  86%|████████▋ | 295/342 [00:13<00:02, 17.27it/s]\n",
      "Training: (loss 0.0599):  87%|████████▋ | 298/342 [00:13<00:02, 19.57it/s]\n",
      "Training: (loss 0.0639):  87%|████████▋ | 298/342 [00:13<00:02, 19.57it/s]\n",
      "Training: (loss -0.0029):  87%|████████▋ | 298/342 [00:13<00:02, 19.57it/s]\n",
      "Training: (loss 0.0819):  87%|████████▋ | 298/342 [00:13<00:02, 19.57it/s] \n",
      "Training: (loss 0.0819):  88%|████████▊ | 301/342 [00:13<00:02, 20.44it/s]\n",
      "Training: (loss 0.4877):  88%|████████▊ | 301/342 [00:13<00:02, 20.44it/s]\n",
      "Training: (loss 0.5496):  88%|████████▊ | 301/342 [00:13<00:02, 20.44it/s]\n",
      "Training: (loss 0.1999):  88%|████████▊ | 301/342 [00:14<00:02, 20.44it/s]\n",
      "Training: (loss 0.1999):  89%|████████▉ | 304/342 [00:14<00:01, 19.17it/s]\n",
      "Training: (loss 0.5679):  89%|████████▉ | 304/342 [00:14<00:01, 19.17it/s]\n",
      "Training: (loss 0.1276):  89%|████████▉ | 304/342 [00:14<00:01, 19.17it/s]\n",
      "Training: (loss 0.1276):  89%|████████▉ | 306/342 [00:14<00:02, 17.18it/s]\n",
      "Training: (loss 0.4877):  89%|████████▉ | 306/342 [00:14<00:02, 17.18it/s]\n",
      "Training: (loss -0.0032):  89%|████████▉ | 306/342 [00:14<00:02, 17.18it/s]\n",
      "Training: (loss -0.0032):  90%|█████████ | 308/342 [00:14<00:02, 13.30it/s]\n",
      "Training: (loss -0.0032):  90%|█████████ | 308/342 [00:14<00:02, 13.30it/s]\n",
      "Training: (loss 0.1514):  90%|█████████ | 308/342 [00:14<00:02, 13.30it/s] \n",
      "Training: (loss 0.1160):  90%|█████████ | 308/342 [00:14<00:02, 13.30it/s]\n",
      "Training: (loss 0.1160):  91%|█████████ | 311/342 [00:14<00:01, 16.17it/s]\n",
      "Training: (loss 0.0292):  91%|█████████ | 311/342 [00:14<00:01, 16.17it/s]\n",
      "Training: (loss 0.0154):  91%|█████████ | 311/342 [00:14<00:01, 16.17it/s]\n",
      "Training: (loss 0.5108):  91%|█████████ | 311/342 [00:14<00:01, 16.17it/s]\n",
      "Training: (loss 0.5108):  92%|█████████▏| 314/342 [00:14<00:01, 17.76it/s]\n",
      "Training: (loss 0.3202):  92%|█████████▏| 314/342 [00:14<00:01, 17.76it/s]\n",
      "Training: (loss 0.0488):  92%|█████████▏| 314/342 [00:14<00:01, 17.76it/s]\n",
      "Training: (loss 0.0488):  92%|█████████▏| 316/342 [00:14<00:01, 16.77it/s]\n",
      "Training: (loss 0.1127):  92%|█████████▏| 316/342 [00:14<00:01, 16.77it/s]\n",
      "Training: (loss 0.0009):  92%|█████████▏| 316/342 [00:14<00:01, 16.77it/s]\n",
      "Training: (loss 0.0009):  93%|█████████▎| 318/342 [00:14<00:01, 17.44it/s]\n",
      "Training: (loss 0.1276):  93%|█████████▎| 318/342 [00:14<00:01, 17.44it/s]\n",
      "Training: (loss -0.0323):  93%|█████████▎| 318/342 [00:15<00:01, 17.44it/s]\n",
      "Training: (loss 0.3022):  93%|█████████▎| 318/342 [00:15<00:01, 17.44it/s] \n",
      "Training: (loss 0.3022):  94%|█████████▍| 321/342 [00:15<00:01, 18.83it/s]\n",
      "Training: (loss 0.7819):  94%|█████████▍| 321/342 [00:15<00:01, 18.83it/s]\n",
      "Training: (loss 0.4771):  94%|█████████▍| 321/342 [00:15<00:01, 18.83it/s]\n",
      "Training: (loss 0.5909):  94%|█████████▍| 321/342 [00:15<00:01, 18.83it/s]\n",
      "Training: (loss 0.5909):  95%|█████████▍| 324/342 [00:15<00:00, 19.48it/s]\n",
      "Training: (loss 0.1008):  95%|█████████▍| 324/342 [00:15<00:00, 19.48it/s]\n",
      "Training: (loss 0.0488):  95%|█████████▍| 324/342 [00:15<00:00, 19.48it/s]\n",
      "Training: (loss 0.0389):  95%|█████████▍| 324/342 [00:15<00:00, 19.48it/s]\n",
      "Training: (loss 0.0389):  96%|█████████▌| 327/342 [00:15<00:00, 20.44it/s]\n",
      "Training: (loss 0.0936):  96%|█████████▌| 327/342 [00:15<00:00, 20.44it/s]\n",
      "Training: (loss 0.6212):  96%|█████████▌| 327/342 [00:15<00:00, 20.44it/s]\n",
      "Training: (loss 0.0702):  96%|█████████▌| 327/342 [00:15<00:00, 20.44it/s]\n",
      "Training: (loss 0.0702):  96%|█████████▋| 330/342 [00:15<00:00, 20.96it/s]\n",
      "Training: (loss 0.0168):  96%|█████████▋| 330/342 [00:15<00:00, 20.96it/s]\n",
      "Training: (loss 0.2106):  96%|█████████▋| 330/342 [00:15<00:00, 20.96it/s]\n",
      "Training: (loss 0.0116):  96%|█████████▋| 330/342 [00:15<00:00, 20.96it/s]\n",
      "Training: (loss 0.0116):  97%|█████████▋| 333/342 [00:15<00:00, 21.67it/s]\n",
      "Training: (loss 0.1280):  97%|█████████▋| 333/342 [00:15<00:00, 21.67it/s]\n",
      "Training: (loss 0.5716):  97%|█████████▋| 333/342 [00:15<00:00, 21.67it/s]\n",
      "Training: (loss 0.0908):  97%|█████████▋| 333/342 [00:15<00:00, 21.67it/s]\n",
      "Training: (loss 0.0908):  98%|█████████▊| 336/342 [00:15<00:00, 20.90it/s]\n",
      "Training: (loss 0.0912):  98%|█████████▊| 336/342 [00:15<00:00, 20.90it/s]\n",
      "Training: (loss 0.1127):  98%|█████████▊| 336/342 [00:15<00:00, 20.90it/s]\n",
      "Training: (loss -0.0115):  98%|█████████▊| 336/342 [00:15<00:00, 20.90it/s]\n",
      "Training: (loss -0.0115):  99%|█████████▉| 339/342 [00:15<00:00, 20.78it/s]\n",
      "Training: (loss 0.4200):  99%|█████████▉| 339/342 [00:15<00:00, 20.78it/s] \n",
      "Training: (loss 0.0328):  99%|█████████▉| 339/342 [00:16<00:00, 20.78it/s]\n",
      "Training: (loss 0.0551):  99%|█████████▉| 339/342 [00:16<00:00, 20.78it/s]\n",
      "Training: (loss 0.0551): 100%|██████████| 342/342 [00:16<00:00, 20.36it/s]\n",
      "                                                                          \n",
      "Validation:   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.5716):   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.0132):   0%|          | 0/39 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.1784441102492182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation: (loss 0.1121):   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.1121):   8%|▊         | 3/39 [00:00<00:01, 28.49it/s]\n",
      "Validation: (loss 0.5212):   8%|▊         | 3/39 [00:00<00:01, 28.49it/s]\n",
      "Validation: (loss 0.3202):   8%|▊         | 3/39 [00:00<00:01, 28.49it/s]\n",
      "Validation: (loss 0.0820):   8%|▊         | 3/39 [00:00<00:01, 28.49it/s]\n",
      "Validation: (loss 0.0820):  15%|█▌        | 6/39 [00:00<00:01, 23.40it/s]\n",
      "Validation: (loss 0.0551):  15%|█▌        | 6/39 [00:00<00:01, 23.40it/s]\n",
      "Validation: (loss -0.0286):  15%|█▌        | 6/39 [00:00<00:01, 23.40it/s]\n",
      "Validation: (loss 0.1070):  15%|█▌        | 6/39 [00:00<00:01, 23.40it/s] \n",
      "Validation: (loss 0.0147):  15%|█▌        | 6/39 [00:00<00:01, 23.40it/s]\n",
      "Validation: (loss -0.0508):  15%|█▌        | 6/39 [00:00<00:01, 23.40it/s]\n",
      "Validation: (loss -0.0508):  28%|██▊       | 11/39 [00:00<00:00, 33.33it/s]\n",
      "Validation: (loss 0.6837):  28%|██▊       | 11/39 [00:00<00:00, 33.33it/s] \n",
      "Validation: (loss 0.1514):  28%|██▊       | 11/39 [00:00<00:00, 33.33it/s]\n",
      "Validation: (loss 0.0069):  28%|██▊       | 11/39 [00:00<00:00, 33.33it/s]\n",
      "Validation: (loss -0.0019):  28%|██▊       | 11/39 [00:00<00:00, 33.33it/s]\n",
      "Validation: (loss 0.0908):  28%|██▊       | 11/39 [00:00<00:00, 33.33it/s] \n",
      "Validation: (loss 0.0908):  41%|████      | 16/39 [00:00<00:00, 38.15it/s]\n",
      "Validation: (loss 0.0969):  41%|████      | 16/39 [00:00<00:00, 38.15it/s]\n",
      "Validation: (loss 0.0304):  41%|████      | 16/39 [00:00<00:00, 38.15it/s]\n",
      "Validation: (loss 0.0046):  41%|████      | 16/39 [00:00<00:00, 38.15it/s]\n",
      "Validation: (loss 0.6212):  41%|████      | 16/39 [00:00<00:00, 38.15it/s]\n",
      "Validation: (loss 0.6212):  51%|█████▏    | 20/39 [00:00<00:00, 26.56it/s]\n",
      "Validation: (loss 0.1431):  51%|█████▏    | 20/39 [00:00<00:00, 26.56it/s]\n",
      "Validation: (loss 0.0959):  51%|█████▏    | 20/39 [00:00<00:00, 26.56it/s]\n",
      "Validation: (loss 0.0069):  51%|█████▏    | 20/39 [00:00<00:00, 26.56it/s]\n",
      "Validation: (loss 0.0463):  51%|█████▏    | 20/39 [00:00<00:00, 26.56it/s]\n",
      "Validation: (loss 0.0463):  62%|██████▏   | 24/39 [00:00<00:00, 23.49it/s]\n",
      "Validation: (loss 0.0173):  62%|██████▏   | 24/39 [00:00<00:00, 23.49it/s]\n",
      "Validation: (loss 0.5909):  62%|██████▏   | 24/39 [00:01<00:00, 23.49it/s]\n",
      "Validation: (loss 0.2383):  62%|██████▏   | 24/39 [00:01<00:00, 23.49it/s]\n",
      "Validation: (loss 0.2383):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.1214):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.2124):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.0488):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.0929):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.7133):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.0639):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.0712):  69%|██████▉   | 27/39 [00:01<00:00, 24.87it/s]\n",
      "Validation: (loss 0.0712):  87%|████████▋ | 34/39 [00:01<00:00, 35.16it/s]\n",
      "Validation: (loss 0.0431):  87%|████████▋ | 34/39 [00:01<00:00, 35.16it/s]\n",
      "Validation: (loss 0.0043):  87%|████████▋ | 34/39 [00:01<00:00, 35.16it/s]\n",
      "Validation: (loss 0.0883):  87%|████████▋ | 34/39 [00:01<00:00, 35.16it/s]\n",
      "Validation: (loss 0.5467):  87%|████████▋ | 34/39 [00:01<00:00, 35.16it/s]\n",
      "Validation: (loss 0.0168):  87%|████████▋ | 34/39 [00:01<00:00, 35.16it/s]\n",
      "Progress:  50%|█████     | 1/2 [00:17<00:17, 17.28s/it]                   \n",
      "Training:   0%|          | 0/342 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg validation loss: 0.16829593632465753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Training: (loss 0.4200):   0%|          | 0/342 [00:00<?, ?it/s]\n",
      "Training: (loss 0.0592):   0%|          | 0/342 [00:00<?, ?it/s]\n",
      "Training: (loss 0.0592):   1%|          | 2/342 [00:00<00:18, 18.52it/s]\n",
      "Training: (loss 0.1073):   1%|          | 2/342 [00:00<00:18, 18.52it/s]\n",
      "Training: (loss 0.2079):   1%|          | 2/342 [00:00<00:18, 18.52it/s]\n",
      "Training: (loss 0.5108):   1%|          | 2/342 [00:00<00:18, 18.52it/s]\n",
      "Training: (loss 0.5108):   1%|▏         | 5/342 [00:00<00:16, 20.40it/s]\n",
      "Training: (loss 0.0141):   1%|▏         | 5/342 [00:00<00:16, 20.40it/s]\n",
      "Training: (loss 0.0116):   1%|▏         | 5/342 [00:00<00:16, 20.40it/s]\n",
      "Training: (loss 0.1881):   1%|▏         | 5/342 [00:00<00:16, 20.40it/s]\n",
      "Training: (loss 0.1881):   2%|▏         | 8/342 [00:00<00:18, 18.06it/s]\n",
      "Training: (loss 0.0233):   2%|▏         | 8/342 [00:00<00:18, 18.06it/s]\n",
      "Training: (loss 0.0935):   2%|▏         | 8/342 [00:00<00:18, 18.06it/s]\n",
      "Training: (loss -0.0286):   2%|▏         | 8/342 [00:00<00:18, 18.06it/s]\n",
      "Training: (loss -0.0436):   2%|▏         | 8/342 [00:00<00:18, 18.06it/s]\n",
      "Training: (loss -0.0436):   4%|▎         | 12/342 [00:00<00:14, 22.89it/s]\n",
      "Training: (loss 0.0712):   4%|▎         | 12/342 [00:00<00:14, 22.89it/s] \n",
      "Training: (loss 0.5108):   4%|▎         | 12/342 [00:00<00:14, 22.89it/s]\n",
      "Training: (loss 0.0389):   4%|▎         | 12/342 [00:00<00:14, 22.89it/s]\n",
      "Training: (loss 0.0389):   4%|▍         | 15/342 [00:00<00:13, 24.84it/s]\n",
      "Training: (loss 0.0702):   4%|▍         | 15/342 [00:00<00:13, 24.84it/s]\n",
      "Training: (loss -0.0024):   4%|▍         | 15/342 [00:00<00:13, 24.84it/s]\n",
      "Training: (loss 0.4200):   4%|▍         | 15/342 [00:00<00:13, 24.84it/s] \n",
      "Training: (loss 0.4200):   5%|▌         | 18/342 [00:00<00:12, 25.80it/s]\n",
      "Training: (loss 0.5326):   5%|▌         | 18/342 [00:00<00:12, 25.80it/s]\n",
      "Training: (loss -0.0305):   5%|▌         | 18/342 [00:00<00:12, 25.80it/s]\n",
      "Training: (loss 0.4771):   5%|▌         | 18/342 [00:00<00:12, 25.80it/s] \n",
      "Training: (loss 0.4771):   6%|▌         | 21/342 [00:00<00:12, 26.35it/s]\n",
      "Training: (loss 0.1160):   6%|▌         | 21/342 [00:00<00:12, 26.35it/s]\n",
      "Training: (loss 0.0910):   6%|▌         | 21/342 [00:01<00:12, 26.35it/s]\n",
      "Training: (loss 0.0043):   6%|▌         | 21/342 [00:01<00:12, 26.35it/s]\n",
      "Training: (loss 0.0043):   7%|▋         | 24/342 [00:01<00:15, 21.00it/s]\n",
      "Training: (loss -0.0520):   7%|▋         | 24/342 [00:01<00:15, 21.00it/s]\n",
      "Training: (loss 0.2383):   7%|▋         | 24/342 [00:01<00:15, 21.00it/s] \n",
      "Training: (loss 0.1008):   7%|▋         | 24/342 [00:01<00:15, 21.00it/s]\n",
      "Training: (loss 0.1008):   8%|▊         | 27/342 [00:01<00:14, 21.43it/s]\n",
      "Training: (loss 0.5212):   8%|▊         | 27/342 [00:01<00:14, 21.43it/s]\n",
      "Training: (loss 0.0630):   8%|▊         | 27/342 [00:01<00:14, 21.43it/s]\n",
      "Training: (loss 0.0321):   8%|▊         | 27/342 [00:01<00:14, 21.43it/s]\n",
      "Training: (loss 0.0321):   9%|▉         | 30/342 [00:01<00:14, 21.63it/s]\n",
      "Training: (loss 0.1276):   9%|▉         | 30/342 [00:01<00:14, 21.63it/s]\n",
      "Training: (loss 0.0702):   9%|▉         | 30/342 [00:01<00:14, 21.63it/s]\n",
      "Training: (loss 0.1121):   9%|▉         | 30/342 [00:01<00:14, 21.63it/s]\n",
      "Training: (loss 0.1121):  10%|▉         | 33/342 [00:01<00:13, 22.96it/s]\n",
      "Training: (loss 0.0959):  10%|▉         | 33/342 [00:01<00:13, 22.96it/s]\n",
      "Training: (loss 0.5496):  10%|▉         | 33/342 [00:01<00:13, 22.96it/s]\n",
      "Training: (loss -0.0323):  10%|▉         | 33/342 [00:01<00:13, 22.96it/s]\n",
      "Training: (loss 0.0791):  10%|▉         | 33/342 [00:01<00:13, 22.96it/s] \n",
      "Training: (loss 0.0791):  11%|█         | 37/342 [00:01<00:11, 25.43it/s]\n",
      "Training: (loss -0.0205):  11%|█         | 37/342 [00:01<00:11, 25.43it/s]\n",
      "Training: (loss -0.0024):  11%|█         | 37/342 [00:01<00:11, 25.43it/s]\n",
      "Training: (loss 0.1280):  11%|█         | 37/342 [00:01<00:11, 25.43it/s] \n",
      "Training: (loss 0.1280):  12%|█▏        | 40/342 [00:01<00:12, 24.58it/s]\n",
      "Training: (loss 0.0599):  12%|█▏        | 40/342 [00:01<00:12, 24.58it/s]\n",
      "Training: (loss 0.1127):  12%|█▏        | 40/342 [00:01<00:12, 24.58it/s]\n",
      "Training: (loss 0.2985):  12%|█▏        | 40/342 [00:01<00:12, 24.58it/s]\n",
      "Training: (loss -0.0029):  12%|█▏        | 40/342 [00:01<00:12, 24.58it/s]\n",
      "Training: (loss -0.0029):  13%|█▎        | 44/342 [00:01<00:11, 26.80it/s]\n",
      "Training: (loss 0.0450):  13%|█▎        | 44/342 [00:01<00:11, 26.80it/s] \n",
      "Training: (loss 0.0935):  13%|█▎        | 44/342 [00:01<00:11, 26.80it/s]\n",
      "Training: (loss -0.0205):  13%|█▎        | 44/342 [00:01<00:11, 26.80it/s]\n",
      "Training: (loss -0.0205):  14%|█▎        | 47/342 [00:01<00:11, 25.22it/s]\n",
      "Training: (loss 0.0009):  14%|█▎        | 47/342 [00:02<00:11, 25.22it/s] \n",
      "Training: (loss 0.0011):  14%|█▎        | 47/342 [00:02<00:11, 25.22it/s]\n",
      "Training: (loss 0.0450):  14%|█▎        | 47/342 [00:02<00:11, 25.22it/s]\n",
      "Training: (loss 0.0450):  15%|█▍        | 50/342 [00:02<00:14, 20.04it/s]\n",
      "Training: (loss 0.0936):  15%|█▍        | 50/342 [00:02<00:14, 20.04it/s]\n",
      "Training: (loss 0.5951):  15%|█▍        | 50/342 [00:02<00:14, 20.04it/s]\n",
      "Training: (loss -0.0089):  15%|█▍        | 50/342 [00:02<00:14, 20.04it/s]\n",
      "Training: (loss -0.0089):  15%|█▌        | 53/342 [00:02<00:14, 20.64it/s]\n",
      "Training: (loss 0.0361):  15%|█▌        | 53/342 [00:02<00:14, 20.64it/s] \n",
      "Training: (loss 0.0636):  15%|█▌        | 53/342 [00:02<00:14, 20.64it/s]\n",
      "Training: (loss 0.0819):  15%|█▌        | 53/342 [00:02<00:14, 20.64it/s]\n",
      "Training: (loss 0.0819):  16%|█▋        | 56/342 [00:02<00:16, 16.97it/s]\n",
      "Training: (loss 0.6212):  16%|█▋        | 56/342 [00:02<00:16, 16.97it/s]\n",
      "Training: (loss 0.0639):  16%|█▋        | 56/342 [00:02<00:16, 16.97it/s]\n",
      "Training: (loss 0.0101):  16%|█▋        | 56/342 [00:02<00:16, 16.97it/s]\n",
      "Training: (loss 0.0101):  17%|█▋        | 59/342 [00:02<00:14, 19.15it/s]\n",
      "Training: (loss 0.5951):  17%|█▋        | 59/342 [00:02<00:14, 19.15it/s]\n",
      "Training: (loss 0.5716):  17%|█▋        | 59/342 [00:02<00:14, 19.15it/s]\n",
      "Training: (loss 0.2983):  17%|█▋        | 59/342 [00:02<00:14, 19.15it/s]\n",
      "Training: (loss 0.2983):  18%|█▊        | 62/342 [00:02<00:16, 16.97it/s]\n",
      "Training: (loss 0.0147):  18%|█▊        | 62/342 [00:02<00:16, 16.97it/s]\n",
      "Training: (loss 0.1071):  18%|█▊        | 62/342 [00:03<00:16, 16.97it/s]\n",
      "Training: (loss 0.1071):  19%|█▊        | 64/342 [00:03<00:16, 17.36it/s]\n",
      "Training: (loss 0.1070):  19%|█▊        | 64/342 [00:03<00:16, 17.36it/s]\n",
      "Training: (loss 0.0846):  19%|█▊        | 64/342 [00:03<00:16, 17.36it/s]\n",
      "Training: (loss 0.0154):  19%|█▊        | 64/342 [00:03<00:16, 17.36it/s]\n",
      "Training: (loss 0.0154):  20%|█▉        | 67/342 [00:03<00:16, 16.55it/s]\n",
      "Training: (loss 0.0154):  20%|█▉        | 67/342 [00:03<00:16, 16.55it/s]\n",
      "Training: (loss 0.0132):  20%|█▉        | 67/342 [00:03<00:16, 16.55it/s]\n",
      "Training: (loss 0.0630):  20%|█▉        | 67/342 [00:03<00:16, 16.55it/s]\n",
      "Training: (loss 0.0630):  20%|██        | 70/342 [00:03<00:15, 17.77it/s]\n",
      "Training: (loss 0.0361):  20%|██        | 70/342 [00:03<00:15, 17.77it/s]\n",
      "Training: (loss 0.5679):  20%|██        | 70/342 [00:03<00:15, 17.77it/s]\n",
      "Training: (loss 0.5679):  21%|██        | 72/342 [00:03<00:15, 17.98it/s]\n",
      "Training: (loss 0.2871):  21%|██        | 72/342 [00:03<00:15, 17.98it/s]\n",
      "Training: (loss 0.4200):  21%|██        | 72/342 [00:03<00:15, 17.98it/s]\n",
      "Training: (loss 0.4200):  22%|██▏       | 74/342 [00:03<00:16, 16.36it/s]\n",
      "Training: (loss 0.0908):  22%|██▏       | 74/342 [00:03<00:16, 16.36it/s]\n",
      "Training: (loss 0.5212):  22%|██▏       | 74/342 [00:03<00:16, 16.36it/s]\n",
      "Training: (loss 0.5212):  22%|██▏       | 76/342 [00:03<00:15, 17.16it/s]\n",
      "Training: (loss 0.0101):  22%|██▏       | 76/342 [00:03<00:15, 17.16it/s]\n",
      "Training: (loss 0.1777):  22%|██▏       | 76/342 [00:03<00:15, 17.16it/s]\n",
      "Training: (loss 0.1777):  23%|██▎       | 78/342 [00:03<00:14, 17.77it/s]\n",
      "Training: (loss 0.1035):  23%|██▎       | 78/342 [00:03<00:14, 17.77it/s]\n",
      "Training: (loss 0.0116):  23%|██▎       | 78/342 [00:03<00:14, 17.77it/s]\n",
      "Training: (loss 0.0116):  23%|██▎       | 80/342 [00:03<00:15, 17.37it/s]\n",
      "Training: (loss 0.5496):  23%|██▎       | 80/342 [00:03<00:15, 17.37it/s]\n",
      "Training: (loss 0.0034):  23%|██▎       | 80/342 [00:04<00:15, 17.37it/s]\n",
      "Training: (loss 0.2405):  23%|██▎       | 80/342 [00:04<00:15, 17.37it/s]\n",
      "Training: (loss 0.2405):  24%|██▍       | 83/342 [00:04<00:13, 19.79it/s]\n",
      "Training: (loss 0.0912):  24%|██▍       | 83/342 [00:04<00:13, 19.79it/s]\n",
      "Training: (loss 0.0304):  24%|██▍       | 83/342 [00:04<00:13, 19.79it/s]\n",
      "Training: (loss 0.1881):  24%|██▍       | 83/342 [00:04<00:13, 19.79it/s]\n",
      "Training: (loss 0.1881):  25%|██▌       | 86/342 [00:04<00:11, 21.99it/s]\n",
      "Training: (loss 0.1777):  25%|██▌       | 86/342 [00:04<00:11, 21.99it/s]\n",
      "Training: (loss 0.0440):  25%|██▌       | 86/342 [00:04<00:11, 21.99it/s]\n",
      "Training: (loss 0.0694):  25%|██▌       | 86/342 [00:04<00:11, 21.99it/s]\n",
      "Training: (loss 0.7819):  25%|██▌       | 86/342 [00:04<00:11, 21.99it/s]\n",
      "Training: (loss 0.7819):  26%|██▋       | 90/342 [00:04<00:11, 21.46it/s]\n",
      "Training: (loss 0.3166):  26%|██▋       | 90/342 [00:04<00:11, 21.46it/s]\n",
      "Training: (loss 0.1121):  26%|██▋       | 90/342 [00:04<00:11, 21.46it/s]\n",
      "Training: (loss 0.1999):  26%|██▋       | 90/342 [00:04<00:11, 21.46it/s]\n",
      "Training: (loss 0.1999):  27%|██▋       | 93/342 [00:04<00:11, 22.37it/s]\n",
      "Training: (loss 0.0154):  27%|██▋       | 93/342 [00:04<00:11, 22.37it/s]\n",
      "Training: (loss 0.0450):  27%|██▋       | 93/342 [00:04<00:11, 22.37it/s]\n",
      "Training: (loss 0.3022):  27%|██▋       | 93/342 [00:04<00:11, 22.37it/s]\n",
      "Training: (loss 0.3022):  28%|██▊       | 96/342 [00:04<00:10, 23.45it/s]\n",
      "Training: (loss 0.2983):  28%|██▊       | 96/342 [00:04<00:10, 23.45it/s]\n",
      "Training: (loss 0.0147):  28%|██▊       | 96/342 [00:04<00:10, 23.45it/s]\n",
      "Training: (loss 0.0702):  28%|██▊       | 96/342 [00:04<00:10, 23.45it/s]\n",
      "Training: (loss 0.6837):  28%|██▊       | 96/342 [00:04<00:10, 23.45it/s]\n",
      "Training: (loss 0.6837):  29%|██▉       | 100/342 [00:04<00:09, 25.31it/s]\n",
      "Training: (loss 0.1073):  29%|██▉       | 100/342 [00:04<00:09, 25.31it/s]\n",
      "Training: (loss 0.1964):  29%|██▉       | 100/342 [00:04<00:09, 25.31it/s]\n",
      "Training: (loss 0.0431):  29%|██▉       | 100/342 [00:04<00:09, 25.31it/s]\n",
      "Training: (loss 0.0431):  30%|███       | 103/342 [00:04<00:09, 25.74it/s]\n",
      "Training: (loss 0.0233):  30%|███       | 103/342 [00:04<00:09, 25.74it/s]\n",
      "Training: (loss 0.3638):  30%|███       | 103/342 [00:04<00:09, 25.74it/s]\n",
      "Training: (loss 0.1280):  30%|███       | 103/342 [00:05<00:09, 25.74it/s]\n",
      "Training: (loss 0.1280):  31%|███       | 106/342 [00:05<00:09, 24.47it/s]\n",
      "Training: (loss -0.0436):  31%|███       | 106/342 [00:05<00:09, 24.47it/s]\n",
      "Training: (loss 0.2325):  31%|███       | 106/342 [00:05<00:09, 24.47it/s] \n",
      "Training: (loss 0.0233):  31%|███       | 106/342 [00:05<00:09, 24.47it/s]\n",
      "Training: (loss 0.0141):  31%|███       | 106/342 [00:05<00:09, 24.47it/s]\n",
      "Training: (loss 0.0141):  32%|███▏      | 110/342 [00:05<00:08, 26.28it/s]\n",
      "Training: (loss 0.7133):  32%|███▏      | 110/342 [00:05<00:08, 26.28it/s]\n",
      "Training: (loss 0.1124):  32%|███▏      | 110/342 [00:05<00:08, 26.28it/s]\n",
      "Training: (loss 0.0820):  32%|███▏      | 110/342 [00:05<00:08, 26.28it/s]\n",
      "Training: (loss 0.0820):  33%|███▎      | 113/342 [00:05<00:10, 21.20it/s]\n",
      "Training: (loss 0.3638):  33%|███▎      | 113/342 [00:05<00:10, 21.20it/s]\n",
      "Training: (loss 0.1214):  33%|███▎      | 113/342 [00:05<00:10, 21.20it/s]\n",
      "Training: (loss 0.6050):  33%|███▎      | 113/342 [00:05<00:10, 21.20it/s]\n",
      "Training: (loss 0.6050):  34%|███▍      | 116/342 [00:05<00:11, 19.49it/s]\n",
      "Training: (loss 0.1008):  34%|███▍      | 116/342 [00:05<00:11, 19.49it/s]\n",
      "Training: (loss 0.0929):  34%|███▍      | 116/342 [00:05<00:11, 19.49it/s]\n",
      "Training: (loss -0.0115):  34%|███▍      | 116/342 [00:05<00:11, 19.49it/s]\n",
      "Training: (loss -0.0115):  35%|███▍      | 119/342 [00:05<00:11, 19.24it/s]\n",
      "Training: (loss -0.0520):  35%|███▍      | 119/342 [00:05<00:11, 19.24it/s]\n",
      "Training: (loss 0.0328):  35%|███▍      | 119/342 [00:05<00:11, 19.24it/s] \n",
      "Training: (loss -0.0226):  35%|███▍      | 119/342 [00:05<00:11, 19.24it/s]\n",
      "Training: (loss -0.0226):  36%|███▌      | 122/342 [00:05<00:10, 20.27it/s]\n",
      "Training: (loss -0.0273):  36%|███▌      | 122/342 [00:05<00:10, 20.27it/s]\n",
      "Training: (loss 0.1964):  36%|███▌      | 122/342 [00:05<00:10, 20.27it/s] \n",
      "Training: (loss 0.0034):  36%|███▌      | 122/342 [00:05<00:10, 20.27it/s]\n",
      "Training: (loss 0.0034):  37%|███▋      | 125/342 [00:05<00:10, 21.45it/s]\n",
      "Training: (loss 0.1514):  37%|███▋      | 125/342 [00:05<00:10, 21.45it/s]\n",
      "Training: (loss -0.0305):  37%|███▋      | 125/342 [00:06<00:10, 21.45it/s]\n",
      "Training: (loss 0.2871):  37%|███▋      | 125/342 [00:06<00:10, 21.45it/s] \n",
      "Training: (loss 0.2871):  37%|███▋      | 128/342 [00:06<00:09, 21.62it/s]\n",
      "Training: (loss 0.1881):  37%|███▋      | 128/342 [00:06<00:09, 21.62it/s]\n",
      "Training: (loss 0.0636):  37%|███▋      | 128/342 [00:06<00:09, 21.62it/s]\n",
      "Training: (loss 0.1455):  37%|███▋      | 128/342 [00:06<00:09, 21.62it/s]\n",
      "Training: (loss 0.1455):  38%|███▊      | 131/342 [00:06<00:09, 21.14it/s]\n",
      "Training: (loss 0.0910):  38%|███▊      | 131/342 [00:06<00:09, 21.14it/s]\n",
      "Training: (loss 0.0604):  38%|███▊      | 131/342 [00:06<00:09, 21.14it/s]\n",
      "Training: (loss 0.1035):  38%|███▊      | 131/342 [00:06<00:09, 21.14it/s]\n",
      "Training: (loss 0.1035):  39%|███▉      | 134/342 [00:06<00:11, 17.57it/s]\n",
      "Training: (loss 0.8518):  39%|███▉      | 134/342 [00:06<00:11, 17.57it/s]\n",
      "Training: (loss 0.0304):  39%|███▉      | 134/342 [00:06<00:11, 17.57it/s]\n",
      "Training: (loss 0.5467):  39%|███▉      | 134/342 [00:06<00:11, 17.57it/s]\n",
      "Training: (loss 0.5467):  40%|████      | 137/342 [00:06<00:10, 19.07it/s]\n",
      "Training: (loss -0.0226):  40%|████      | 137/342 [00:06<00:10, 19.07it/s]\n",
      "Training: (loss 0.0639):  40%|████      | 137/342 [00:06<00:10, 19.07it/s] \n",
      "Training: (loss 0.0869):  40%|████      | 137/342 [00:06<00:10, 19.07it/s]\n",
      "Training: (loss 0.0599):  40%|████      | 137/342 [00:06<00:10, 19.07it/s]\n",
      "Training: (loss 0.0599):  41%|████      | 141/342 [00:06<00:09, 20.79it/s]\n",
      "Training: (loss 0.0694):  41%|████      | 141/342 [00:06<00:09, 20.79it/s]\n",
      "Training: (loss 0.7133):  41%|████      | 141/342 [00:06<00:09, 20.79it/s]\n",
      "Training: (loss 0.8524):  41%|████      | 141/342 [00:06<00:09, 20.79it/s]\n",
      "Training: (loss 0.8524):  42%|████▏     | 144/342 [00:06<00:09, 20.49it/s]\n",
      "Training: (loss 0.5716):  42%|████▏     | 144/342 [00:07<00:09, 20.49it/s]\n",
      "Training: (loss 0.0969):  42%|████▏     | 144/342 [00:07<00:09, 20.49it/s]\n",
      "Training: (loss 0.1035):  42%|████▏     | 144/342 [00:07<00:09, 20.49it/s]\n",
      "Training: (loss 0.1035):  43%|████▎     | 147/342 [00:07<00:13, 14.91it/s]\n",
      "Training: (loss 0.0292):  43%|████▎     | 147/342 [00:07<00:13, 14.91it/s]\n",
      "Training: (loss 0.1124):  43%|████▎     | 147/342 [00:07<00:13, 14.91it/s]\n",
      "Training: (loss -0.0273):  43%|████▎     | 147/342 [00:07<00:13, 14.91it/s]\n",
      "Training: (loss -0.0273):  44%|████▍     | 150/342 [00:07<00:11, 17.10it/s]\n",
      "Training: (loss 0.2871):  44%|████▍     | 150/342 [00:07<00:11, 17.10it/s] \n",
      "Training: (loss 0.0009):  44%|████▍     | 150/342 [00:07<00:11, 17.10it/s]\n",
      "Training: (loss 0.0328):  44%|████▍     | 150/342 [00:07<00:11, 17.10it/s]\n",
      "Training: (loss 0.0328):  45%|████▍     | 153/342 [00:07<00:10, 18.40it/s]\n",
      "Training: (loss 0.0883):  45%|████▍     | 153/342 [00:07<00:10, 18.40it/s]\n",
      "Training: (loss 0.5129):  45%|████▍     | 153/342 [00:07<00:10, 18.40it/s]\n",
      "Training: (loss 0.1216):  45%|████▍     | 153/342 [00:07<00:10, 18.40it/s]\n",
      "Training: (loss 0.1216):  46%|████▌     | 156/342 [00:07<00:09, 18.88it/s]\n",
      "Training: (loss 0.1276):  46%|████▌     | 156/342 [00:07<00:09, 18.88it/s]\n",
      "Training: (loss 0.1280):  46%|████▌     | 156/342 [00:07<00:09, 18.88it/s]\n",
      "Training: (loss 0.2106):  46%|████▌     | 156/342 [00:07<00:09, 18.88it/s]\n",
      "Training: (loss 0.2106):  46%|████▋     | 159/342 [00:07<00:11, 15.88it/s]\n",
      "Training: (loss 0.0328):  46%|████▋     | 159/342 [00:07<00:11, 15.88it/s]\n",
      "Training: (loss 0.0869):  46%|████▋     | 159/342 [00:08<00:11, 15.88it/s]\n",
      "Training: (loss 0.0869):  47%|████▋     | 161/342 [00:08<00:12, 14.54it/s]\n",
      "Training: (loss 0.4877):  47%|████▋     | 161/342 [00:08<00:12, 14.54it/s]\n",
      "Training: (loss 0.0069):  47%|████▋     | 161/342 [00:08<00:12, 14.54it/s]\n",
      "Training: (loss 0.0604):  47%|████▋     | 161/342 [00:08<00:12, 14.54it/s]\n",
      "Training: (loss 0.0604):  48%|████▊     | 164/342 [00:08<00:11, 15.69it/s]\n",
      "Training: (loss 0.0819):  48%|████▊     | 164/342 [00:08<00:11, 15.69it/s]\n",
      "Training: (loss 0.3022):  48%|████▊     | 164/342 [00:08<00:11, 15.69it/s]\n",
      "Training: (loss 0.7819):  48%|████▊     | 164/342 [00:08<00:11, 15.69it/s]\n",
      "Training: (loss 0.7819):  49%|████▉     | 167/342 [00:08<00:09, 17.96it/s]\n",
      "Training: (loss 0.1276):  49%|████▉     | 167/342 [00:08<00:09, 17.96it/s]\n",
      "Training: (loss 0.5129):  49%|████▉     | 167/342 [00:08<00:09, 17.96it/s]\n",
      "Training: (loss 0.2325):  49%|████▉     | 167/342 [00:08<00:09, 17.96it/s]\n",
      "Training: (loss 0.2325):  50%|████▉     | 170/342 [00:08<00:09, 18.43it/s]\n",
      "Training: (loss 0.3567):  50%|████▉     | 170/342 [00:08<00:09, 18.43it/s]\n",
      "Training: (loss 0.2985):  50%|████▉     | 170/342 [00:08<00:09, 18.43it/s]\n",
      "Training: (loss 0.0488):  50%|████▉     | 170/342 [00:08<00:09, 18.43it/s]\n",
      "Training: (loss 0.0488):  51%|█████     | 173/342 [00:08<00:08, 20.00it/s]\n",
      "Training: (loss 0.1124):  51%|█████     | 173/342 [00:08<00:08, 20.00it/s]\n",
      "Training: (loss 0.5108):  51%|█████     | 173/342 [00:08<00:08, 20.00it/s]\n",
      "Training: (loss 0.5679):  51%|█████     | 173/342 [00:08<00:08, 20.00it/s]\n",
      "Training: (loss 0.5679):  51%|█████▏    | 176/342 [00:08<00:07, 21.63it/s]\n",
      "Training: (loss -0.0205):  51%|█████▏    | 176/342 [00:08<00:07, 21.63it/s]\n",
      "Training: (loss -0.0226):  51%|█████▏    | 176/342 [00:08<00:07, 21.63it/s]\n",
      "Training: (loss 0.7819):  51%|█████▏    | 176/342 [00:08<00:07, 21.63it/s] \n",
      "Training: (loss 0.7819):  52%|█████▏    | 179/342 [00:08<00:07, 22.73it/s]\n",
      "Training: (loss 0.4771):  52%|█████▏    | 179/342 [00:08<00:07, 22.73it/s]\n",
      "Training: (loss 0.0348):  52%|█████▏    | 179/342 [00:08<00:07, 22.73it/s]\n",
      "Training: (loss -0.0520):  52%|█████▏    | 179/342 [00:09<00:07, 22.73it/s]\n",
      "Training: (loss -0.0520):  53%|█████▎    | 182/342 [00:09<00:08, 18.72it/s]\n",
      "Training: (loss 0.3202):  53%|█████▎    | 182/342 [00:09<00:08, 18.72it/s] \n",
      "Training: (loss 0.0389):  53%|█████▎    | 182/342 [00:09<00:08, 18.72it/s]\n",
      "Training: (loss 0.0791):  53%|█████▎    | 182/342 [00:09<00:08, 18.72it/s]\n",
      "Training: (loss 0.0791):  54%|█████▍    | 185/342 [00:09<00:09, 17.01it/s]\n",
      "Training: (loss 0.0959):  54%|█████▍    | 185/342 [00:09<00:09, 17.01it/s]\n",
      "Training: (loss 0.3202):  54%|█████▍    | 185/342 [00:09<00:09, 17.01it/s]\n",
      "Training: (loss 0.3166):  54%|█████▍    | 185/342 [00:09<00:09, 17.01it/s]\n",
      "Training: (loss 0.3166):  55%|█████▍    | 188/342 [00:09<00:08, 18.81it/s]\n",
      "Training: (loss 0.0168):  55%|█████▍    | 188/342 [00:09<00:08, 18.81it/s]\n",
      "Training: (loss 0.6837):  55%|█████▍    | 188/342 [00:09<00:08, 18.81it/s]\n",
      "Training: (loss 0.0321):  55%|█████▍    | 188/342 [00:09<00:08, 18.81it/s]\n",
      "Training: (loss 0.0321):  56%|█████▌    | 191/342 [00:09<00:07, 20.08it/s]\n",
      "Training: (loss 0.0846):  56%|█████▌    | 191/342 [00:09<00:07, 20.08it/s]\n",
      "Training: (loss 0.7026):  56%|█████▌    | 191/342 [00:09<00:07, 20.08it/s]\n",
      "Training: (loss -0.0273):  56%|█████▌    | 191/342 [00:09<00:07, 20.08it/s]\n",
      "Training: (loss -0.0273):  57%|█████▋    | 194/342 [00:09<00:07, 19.93it/s]\n",
      "Training: (loss 0.2106):  57%|█████▋    | 194/342 [00:09<00:07, 19.93it/s] \n",
      "Training: (loss 0.2106):  57%|█████▋    | 194/342 [00:09<00:07, 19.93it/s]\n",
      "Training: (loss -0.0323):  57%|█████▋    | 194/342 [00:09<00:07, 19.93it/s]\n",
      "Training: (loss 0.1121):  57%|█████▋    | 194/342 [00:09<00:07, 19.93it/s] \n",
      "Training: (loss 0.1121):  58%|█████▊    | 198/342 [00:09<00:06, 21.22it/s]\n",
      "Training: (loss 0.0173):  58%|█████▊    | 198/342 [00:09<00:06, 21.22it/s]\n",
      "Training: (loss 0.2124):  58%|█████▊    | 198/342 [00:09<00:06, 21.22it/s]\n",
      "Training: (loss 0.0046):  58%|█████▊    | 198/342 [00:10<00:06, 21.22it/s]\n",
      "Training: (loss 0.0046):  59%|█████▉    | 201/342 [00:10<00:06, 20.89it/s]\n",
      "Training: (loss 0.0488):  59%|█████▉    | 201/342 [00:10<00:06, 20.89it/s]\n",
      "Training: (loss 0.4877):  59%|█████▉    | 201/342 [00:10<00:06, 20.89it/s]\n",
      "Training: (loss 0.0712):  59%|█████▉    | 201/342 [00:10<00:06, 20.89it/s]\n",
      "Training: (loss 0.0712):  60%|█████▉    | 204/342 [00:10<00:06, 21.95it/s]\n",
      "Training: (loss 0.0431):  60%|█████▉    | 204/342 [00:10<00:06, 21.95it/s]\n",
      "Training: (loss 0.1999):  60%|█████▉    | 204/342 [00:10<00:06, 21.95it/s]\n",
      "Training: (loss 0.0820):  60%|█████▉    | 204/342 [00:10<00:06, 21.95it/s]\n",
      "Training: (loss 0.0820):  61%|██████    | 207/342 [00:10<00:06, 21.19it/s]\n",
      "Training: (loss -0.0032):  61%|██████    | 207/342 [00:10<00:06, 21.19it/s]\n",
      "Training: (loss 0.0694):  61%|██████    | 207/342 [00:10<00:06, 21.19it/s] \n",
      "Training: (loss 0.0440):  61%|██████    | 207/342 [00:10<00:06, 21.19it/s]\n",
      "Training: (loss 0.0440):  61%|██████▏   | 210/342 [00:10<00:07, 17.38it/s]\n",
      "Training: (loss -0.0115):  61%|██████▏   | 210/342 [00:10<00:07, 17.38it/s]\n",
      "Training: (loss 0.2889):  61%|██████▏   | 210/342 [00:10<00:07, 17.38it/s] \n",
      "Training: (loss 0.0046):  61%|██████▏   | 210/342 [00:10<00:07, 17.38it/s]\n",
      "Training: (loss 0.0046):  62%|██████▏   | 213/342 [00:10<00:07, 18.39it/s]\n",
      "Training: (loss -0.0436):  62%|██████▏   | 213/342 [00:10<00:07, 18.39it/s]\n",
      "Training: (loss 0.0592):  62%|██████▏   | 213/342 [00:10<00:07, 18.39it/s] \n",
      "Training: (loss 0.0592):  63%|██████▎   | 215/342 [00:10<00:06, 18.49it/s]\n",
      "Training: (loss 0.1964):  63%|██████▎   | 215/342 [00:10<00:06, 18.49it/s]\n",
      "Training: (loss 0.0101):  63%|██████▎   | 215/342 [00:10<00:06, 18.49it/s]\n",
      "Training: (loss 0.0936):  63%|██████▎   | 215/342 [00:10<00:06, 18.49it/s]\n",
      "Training: (loss 0.0936):  64%|██████▎   | 218/342 [00:10<00:06, 18.19it/s]\n",
      "Training: (loss 0.2079):  64%|██████▎   | 218/342 [00:10<00:06, 18.19it/s]\n",
      "Training: (loss 0.1121):  64%|██████▎   | 218/342 [00:11<00:06, 18.19it/s]\n",
      "Training: (loss 0.1121):  64%|██████▍   | 220/342 [00:11<00:06, 18.31it/s]\n",
      "Training: (loss 0.1071):  64%|██████▍   | 220/342 [00:11<00:06, 18.31it/s]\n",
      "Training: (loss 0.1777):  64%|██████▍   | 220/342 [00:11<00:06, 18.31it/s]\n",
      "Training: (loss -0.0305):  64%|██████▍   | 220/342 [00:11<00:06, 18.31it/s]\n",
      "Training: (loss -0.0305):  65%|██████▌   | 223/342 [00:11<00:05, 20.99it/s]\n",
      "Training: (loss 0.2889):  65%|██████▌   | 223/342 [00:11<00:05, 20.99it/s] \n",
      "Training: (loss 0.1000):  65%|██████▌   | 223/342 [00:11<00:05, 20.99it/s]\n",
      "Training: (loss 0.0883):  65%|██████▌   | 223/342 [00:11<00:05, 20.99it/s]\n",
      "Training: (loss 0.0883):  66%|██████▌   | 226/342 [00:11<00:05, 21.62it/s]\n",
      "Training: (loss 0.1073):  66%|██████▌   | 226/342 [00:11<00:05, 21.62it/s]\n",
      "Training: (loss -0.0019):  66%|██████▌   | 226/342 [00:11<00:05, 21.62it/s]\n",
      "Training: (loss 0.0141):  66%|██████▌   | 226/342 [00:11<00:05, 21.62it/s] \n",
      "Training: (loss 0.0141):  67%|██████▋   | 229/342 [00:11<00:05, 22.46it/s]\n",
      "Training: (loss 0.0254):  67%|██████▋   | 229/342 [00:11<00:05, 22.46it/s]\n",
      "Training: (loss 0.7026):  67%|██████▋   | 229/342 [00:11<00:05, 22.46it/s]\n",
      "Training: (loss 0.2079):  67%|██████▋   | 229/342 [00:11<00:05, 22.46it/s]\n",
      "Training: (loss 0.2079):  68%|██████▊   | 232/342 [00:11<00:04, 23.00it/s]\n",
      "Training: (loss 0.1216):  68%|██████▊   | 232/342 [00:11<00:04, 23.00it/s]\n",
      "Training: (loss 0.1070):  68%|██████▊   | 232/342 [00:11<00:04, 23.00it/s]\n",
      "Training: (loss 0.5467):  68%|██████▊   | 232/342 [00:11<00:04, 23.00it/s]\n",
      "Training: (loss 0.5467):  69%|██████▊   | 235/342 [00:11<00:04, 23.36it/s]\n",
      "Training: (loss 0.0857):  69%|██████▊   | 235/342 [00:11<00:04, 23.36it/s]\n",
      "Training: (loss 0.0912):  69%|██████▊   | 235/342 [00:11<00:04, 23.36it/s]\n",
      "Training: (loss 0.0857):  69%|██████▊   | 235/342 [00:11<00:04, 23.36it/s]\n",
      "Training: (loss 0.0857):  70%|██████▉   | 238/342 [00:11<00:04, 22.86it/s]\n",
      "Training: (loss 0.1999):  70%|██████▉   | 238/342 [00:11<00:04, 22.86it/s]\n",
      "Training: (loss 0.0857):  70%|██████▉   | 238/342 [00:11<00:04, 22.86it/s]\n",
      "Training: (loss 0.5496):  70%|██████▉   | 238/342 [00:12<00:04, 22.86it/s]\n",
      "Training: (loss 0.5496):  70%|███████   | 241/342 [00:12<00:05, 18.78it/s]\n",
      "Training: (loss 0.0819):  70%|███████   | 241/342 [00:12<00:05, 18.78it/s]\n",
      "Training: (loss 0.5129):  70%|███████   | 241/342 [00:12<00:05, 18.78it/s]\n",
      "Training: (loss 0.0132):  70%|███████   | 241/342 [00:12<00:05, 18.78it/s]\n",
      "Training: (loss 0.0132):  71%|███████▏  | 244/342 [00:12<00:05, 19.02it/s]\n",
      "Training: (loss 0.0936):  71%|███████▏  | 244/342 [00:12<00:05, 19.02it/s]\n",
      "Training: (loss 0.0587):  71%|███████▏  | 244/342 [00:12<00:05, 19.02it/s]\n",
      "Training: (loss 0.3567):  71%|███████▏  | 244/342 [00:12<00:05, 19.02it/s]\n",
      "Training: (loss 0.3567):  72%|███████▏  | 247/342 [00:12<00:04, 20.01it/s]\n",
      "Training: (loss -0.0508):  72%|███████▏  | 247/342 [00:12<00:04, 20.01it/s]\n",
      "Training: (loss 0.0292):  72%|███████▏  | 247/342 [00:12<00:04, 20.01it/s] \n",
      "Training: (loss 0.2889):  72%|███████▏  | 247/342 [00:12<00:04, 20.01it/s]\n",
      "Training: (loss 0.2889):  73%|███████▎  | 250/342 [00:12<00:04, 18.78it/s]\n",
      "Training: (loss -0.0029):  73%|███████▎  | 250/342 [00:12<00:04, 18.78it/s]\n",
      "Training: (loss 0.8524):  73%|███████▎  | 250/342 [00:12<00:04, 18.78it/s] \n",
      "Training: (loss 0.8524):  74%|███████▎  | 252/342 [00:12<00:04, 18.51it/s]\n",
      "Training: (loss 0.1121):  74%|███████▎  | 252/342 [00:12<00:04, 18.51it/s]\n",
      "Training: (loss 0.1008):  74%|███████▎  | 252/342 [00:12<00:04, 18.51it/s]\n",
      "Training: (loss 0.0599):  74%|███████▎  | 252/342 [00:12<00:04, 18.51it/s]\n",
      "Training: (loss 0.0599):  75%|███████▍  | 255/342 [00:12<00:04, 18.99it/s]\n",
      "Training: (loss -0.0323):  75%|███████▍  | 255/342 [00:12<00:04, 18.99it/s]\n",
      "Training: (loss 0.2325):  75%|███████▍  | 255/342 [00:12<00:04, 18.99it/s] \n",
      "Training: (loss 0.0463):  75%|███████▍  | 255/342 [00:12<00:04, 18.99it/s]\n",
      "Training: (loss 0.0463):  75%|███████▌  | 258/342 [00:12<00:04, 20.59it/s]\n",
      "Training: (loss 0.0173):  75%|███████▌  | 258/342 [00:12<00:04, 20.59it/s]\n",
      "Training: (loss 0.1455):  75%|███████▌  | 258/342 [00:12<00:04, 20.59it/s]\n",
      "Training: (loss 0.0034):  75%|███████▌  | 258/342 [00:12<00:04, 20.59it/s]\n",
      "Training: (loss 0.0034):  76%|███████▋  | 261/342 [00:12<00:03, 22.14it/s]\n",
      "Training: (loss 0.0604):  76%|███████▋  | 261/342 [00:13<00:03, 22.14it/s]\n",
      "Training: (loss 0.0935):  76%|███████▋  | 261/342 [00:13<00:03, 22.14it/s]\n",
      "Training: (loss -0.0089):  76%|███████▋  | 261/342 [00:13<00:03, 22.14it/s]\n",
      "Training: (loss -0.0089):  77%|███████▋  | 264/342 [00:13<00:03, 21.90it/s]\n",
      "Training: (loss 0.1127):  77%|███████▋  | 264/342 [00:13<00:03, 21.90it/s] \n",
      "Training: (loss 0.0011):  77%|███████▋  | 264/342 [00:13<00:03, 21.90it/s]\n",
      "Training: (loss -0.0024):  77%|███████▋  | 264/342 [00:13<00:03, 21.90it/s]\n",
      "Training: (loss -0.0024):  78%|███████▊  | 267/342 [00:13<00:03, 19.75it/s]\n",
      "Training: (loss 0.0009):  78%|███████▊  | 267/342 [00:13<00:03, 19.75it/s] \n",
      "Training: (loss 0.0551):  78%|███████▊  | 267/342 [00:13<00:03, 19.75it/s]\n",
      "Training: (loss 0.1431):  78%|███████▊  | 267/342 [00:13<00:03, 19.75it/s]\n",
      "Training: (loss 0.1431):  79%|███████▉  | 270/342 [00:13<00:03, 20.72it/s]\n",
      "Training: (loss 0.1000):  79%|███████▉  | 270/342 [00:13<00:03, 20.72it/s]\n",
      "Training: (loss 0.0791):  79%|███████▉  | 270/342 [00:13<00:03, 20.72it/s]\n",
      "Training: (loss 0.0869):  79%|███████▉  | 270/342 [00:13<00:03, 20.72it/s]\n",
      "Training: (loss 0.0869):  80%|███████▉  | 273/342 [00:13<00:03, 19.23it/s]\n",
      "Training: (loss 0.6212):  80%|███████▉  | 273/342 [00:13<00:03, 19.23it/s]\n",
      "Training: (loss 0.1455):  80%|███████▉  | 273/342 [00:13<00:03, 19.23it/s]\n",
      "Training: (loss -0.0089):  80%|███████▉  | 273/342 [00:13<00:03, 19.23it/s]\n",
      "Training: (loss -0.0089):  81%|████████  | 276/342 [00:13<00:03, 18.30it/s]\n",
      "Training: (loss 0.0587):  81%|████████  | 276/342 [00:13<00:03, 18.30it/s] \n",
      "Training: (loss 0.5909):  81%|████████  | 276/342 [00:13<00:03, 18.30it/s]\n",
      "Training: (loss 0.5909):  81%|████████▏ | 278/342 [00:13<00:03, 17.65it/s]\n",
      "Training: (loss 0.4771):  81%|████████▏ | 278/342 [00:14<00:03, 17.65it/s]\n",
      "Training: (loss 0.1214):  81%|████████▏ | 278/342 [00:14<00:03, 17.65it/s]\n",
      "Training: (loss 0.1214):  82%|████████▏ | 280/342 [00:14<00:03, 16.17it/s]\n",
      "Training: (loss 0.5326):  82%|████████▏ | 280/342 [00:14<00:03, 16.17it/s]\n",
      "Training: (loss -0.0115):  82%|████████▏ | 280/342 [00:14<00:03, 16.17it/s]\n",
      "Training: (loss 0.2124):  82%|████████▏ | 280/342 [00:14<00:03, 16.17it/s] \n",
      "Training: (loss 0.2124):  83%|████████▎ | 283/342 [00:14<00:03, 17.53it/s]\n",
      "Training: (loss 0.8518):  83%|████████▎ | 283/342 [00:14<00:03, 17.53it/s]\n",
      "Training: (loss 0.0011):  83%|████████▎ | 283/342 [00:14<00:03, 17.53it/s]\n",
      "Training: (loss 0.0011):  83%|████████▎ | 285/342 [00:14<00:03, 17.73it/s]\n",
      "Training: (loss 0.5951):  83%|████████▎ | 285/342 [00:14<00:03, 17.73it/s]\n",
      "Training: (loss 0.0116):  83%|████████▎ | 285/342 [00:14<00:03, 17.73it/s]\n",
      "Training: (loss 0.3166):  83%|████████▎ | 285/342 [00:14<00:03, 17.73it/s]\n",
      "Training: (loss 0.3166):  84%|████████▍ | 288/342 [00:14<00:02, 18.35it/s]\n",
      "Training: (loss 0.0929):  84%|████████▍ | 288/342 [00:14<00:02, 18.35it/s]\n",
      "Training: (loss -0.0029):  84%|████████▍ | 288/342 [00:14<00:02, 18.35it/s]\n",
      "Training: (loss -0.0029):  85%|████████▍ | 290/342 [00:14<00:02, 17.86it/s]\n",
      "Training: (loss 0.3638):  85%|████████▍ | 290/342 [00:14<00:02, 17.86it/s] \n",
      "Training: (loss 0.0912):  85%|████████▍ | 290/342 [00:14<00:02, 17.86it/s]\n",
      "Training: (loss 0.3022):  85%|████████▍ | 290/342 [00:14<00:02, 17.86it/s]\n",
      "Training: (loss 0.3022):  86%|████████▌ | 293/342 [00:14<00:02, 16.95it/s]\n",
      "Training: (loss 0.2405):  86%|████████▌ | 293/342 [00:14<00:02, 16.95it/s]\n",
      "Training: (loss 0.0254):  86%|████████▌ | 293/342 [00:15<00:02, 16.95it/s]\n",
      "Training: (loss 0.0254):  86%|████████▋ | 295/342 [00:15<00:04, 11.41it/s]\n",
      "Training: (loss 0.6050):  86%|████████▋ | 295/342 [00:15<00:04, 11.41it/s]\n",
      "Training: (loss 0.1216):  86%|████████▋ | 295/342 [00:15<00:04, 11.41it/s]\n",
      "Training: (loss 0.1216):  87%|████████▋ | 297/342 [00:15<00:03, 12.09it/s]\n",
      "Training: (loss -0.0286):  87%|████████▋ | 297/342 [00:15<00:03, 12.09it/s]\n",
      "Training: (loss 0.1071):  87%|████████▋ | 297/342 [00:15<00:03, 12.09it/s] \n",
      "Training: (loss 0.1071):  87%|████████▋ | 299/342 [00:15<00:03, 12.79it/s]\n",
      "Training: (loss 0.1514):  87%|████████▋ | 299/342 [00:15<00:03, 12.79it/s]\n",
      "Training: (loss 0.0348):  87%|████████▋ | 299/342 [00:15<00:03, 12.79it/s]\n",
      "Training: (loss 0.0348):  88%|████████▊ | 301/342 [00:15<00:04, 10.12it/s]\n",
      "Training: (loss -0.0019):  88%|████████▊ | 301/342 [00:15<00:04, 10.12it/s]\n",
      "Training: (loss 0.8518):  88%|████████▊ | 301/342 [00:15<00:04, 10.12it/s] \n",
      "Training: (loss 0.8518):  89%|████████▊ | 303/342 [00:15<00:03, 10.62it/s]\n",
      "Training: (loss 0.7026):  89%|████████▊ | 303/342 [00:16<00:03, 10.62it/s]\n",
      "Training: (loss -0.0032):  89%|████████▊ | 303/342 [00:16<00:03, 10.62it/s]\n",
      "Training: (loss -0.0032):  89%|████████▉ | 305/342 [00:16<00:03,  9.92it/s]\n",
      "Training: (loss 0.0463):  89%|████████▉ | 305/342 [00:16<00:03,  9.92it/s] \n",
      "Training: (loss 0.0636):  89%|████████▉ | 305/342 [00:16<00:03,  9.92it/s]\n",
      "Training: (loss 0.5909):  89%|████████▉ | 305/342 [00:16<00:03,  9.92it/s]\n",
      "Training: (loss 0.5909):  90%|█████████ | 308/342 [00:16<00:02, 12.51it/s]\n",
      "Training: (loss 0.0846):  90%|█████████ | 308/342 [00:16<00:02, 12.51it/s]\n",
      "Training: (loss 0.0043):  90%|█████████ | 308/342 [00:16<00:02, 12.51it/s]\n",
      "Training: (loss 0.0440):  90%|█████████ | 308/342 [00:16<00:02, 12.51it/s]\n",
      "Training: (loss 0.0440):  91%|█████████ | 311/342 [00:16<00:02, 15.47it/s]\n",
      "Training: (loss 0.0254):  91%|█████████ | 311/342 [00:16<00:02, 15.47it/s]\n",
      "Training: (loss 0.1000):  91%|█████████ | 311/342 [00:16<00:02, 15.47it/s]\n",
      "Training: (loss 0.1000):  92%|█████████▏| 313/342 [00:16<00:01, 16.28it/s]\n",
      "Training: (loss 0.0389):  92%|█████████▏| 313/342 [00:16<00:01, 16.28it/s]\n",
      "Training: (loss -0.0032):  92%|█████████▏| 313/342 [00:16<00:01, 16.28it/s]\n",
      "Training: (loss 0.0292):  92%|█████████▏| 313/342 [00:16<00:01, 16.28it/s] \n",
      "Training: (loss 0.0292):  92%|█████████▏| 316/342 [00:16<00:01, 18.74it/s]\n",
      "Training: (loss 0.3567):  92%|█████████▏| 316/342 [00:16<00:01, 18.74it/s]\n",
      "Training: (loss 0.4877):  92%|█████████▏| 316/342 [00:16<00:01, 18.74it/s]\n",
      "Training: (loss 0.1160):  92%|█████████▏| 316/342 [00:16<00:01, 18.74it/s]\n",
      "Training: (loss 0.1160):  93%|█████████▎| 319/342 [00:16<00:01, 20.33it/s]\n",
      "Training: (loss 0.5326):  93%|█████████▎| 319/342 [00:16<00:01, 20.33it/s]\n",
      "Training: (loss 0.0168):  93%|█████████▎| 319/342 [00:16<00:01, 20.33it/s]\n",
      "Training: (loss 0.0630):  93%|█████████▎| 319/342 [00:16<00:01, 20.33it/s]\n",
      "Training: (loss 0.1160):  93%|█████████▎| 319/342 [00:16<00:01, 20.33it/s]\n",
      "Training: (loss 0.1160):  94%|█████████▍| 323/342 [00:16<00:00, 23.34it/s]\n",
      "Training: (loss -0.0508):  94%|█████████▍| 323/342 [00:16<00:00, 23.34it/s]\n",
      "Training: (loss 0.0969):  94%|█████████▍| 323/342 [00:16<00:00, 23.34it/s] \n",
      "Training: (loss 0.6050):  94%|█████████▍| 323/342 [00:17<00:00, 23.34it/s]\n",
      "Training: (loss 0.6050):  95%|█████████▌| 326/342 [00:17<00:00, 21.46it/s]\n",
      "Training: (loss 0.0587):  95%|█████████▌| 326/342 [00:17<00:00, 21.46it/s]\n",
      "Training: (loss 0.0592):  95%|█████████▌| 326/342 [00:17<00:00, 21.46it/s]\n",
      "Training: (loss 0.0348):  95%|█████████▌| 326/342 [00:17<00:00, 21.46it/s]\n",
      "Training: (loss 0.0348):  96%|█████████▌| 329/342 [00:17<00:00, 22.34it/s]\n",
      "Training: (loss 0.0551):  96%|█████████▌| 329/342 [00:17<00:00, 22.34it/s]\n",
      "Training: (loss 0.8524):  96%|█████████▌| 329/342 [00:17<00:00, 22.34it/s]\n",
      "Training: (loss 0.2405):  96%|█████████▌| 329/342 [00:17<00:00, 22.34it/s]\n",
      "Training: (loss 0.2405):  97%|█████████▋| 332/342 [00:17<00:00, 20.78it/s]\n",
      "Training: (loss 0.1431):  97%|█████████▋| 332/342 [00:17<00:00, 20.78it/s]\n",
      "Training: (loss 0.0321):  97%|█████████▋| 332/342 [00:17<00:00, 20.78it/s]\n",
      "Training: (loss 0.2985):  97%|█████████▋| 332/342 [00:17<00:00, 20.78it/s]\n",
      "Training: (loss 0.2985):  98%|█████████▊| 335/342 [00:17<00:00, 19.04it/s]\n",
      "Training: (loss 0.2983):  98%|█████████▊| 335/342 [00:17<00:00, 19.04it/s]\n",
      "Training: (loss 0.0908):  98%|█████████▊| 335/342 [00:17<00:00, 19.04it/s]\n",
      "Training: (loss 0.2383):  98%|█████████▊| 335/342 [00:17<00:00, 19.04it/s]\n",
      "Training: (loss 0.2383):  99%|█████████▉| 338/342 [00:17<00:00, 20.74it/s]\n",
      "Training: (loss 0.5679):  99%|█████████▉| 338/342 [00:17<00:00, 20.74it/s]\n",
      "Training: (loss 0.1127):  99%|█████████▉| 338/342 [00:17<00:00, 20.74it/s]\n",
      "Training: (loss 0.0361):  99%|█████████▉| 338/342 [00:17<00:00, 20.74it/s]\n",
      "Training: (loss 0.0361): 100%|█████████▉| 341/342 [00:17<00:00, 22.54it/s]\n",
      "Training: (loss 0.0910): 100%|█████████▉| 341/342 [00:17<00:00, 22.54it/s]\n",
      "                                                                          \n",
      "Validation:   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.5716):   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.0132):   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.1121):   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.5212):   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.3202):   0%|          | 0/39 [00:00<?, ?it/s]\n",
      "Validation: (loss 0.3202):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s]\n",
      "Validation: (loss 0.0820):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s]\n",
      "Validation: (loss 0.0551):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s]\n",
      "Validation: (loss -0.0286):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s]\n",
      "Validation: (loss 0.1070):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s] \n",
      "Validation: (loss 0.0147):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg training loss: 0.17654086470778224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation: (loss -0.0508):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s]\n",
      "Validation: (loss 0.6837):  13%|█▎        | 5/39 [00:00<00:00, 45.31it/s] \n",
      "Validation: (loss 0.6837):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss 0.1514):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss 0.0069):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss -0.0019):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss 0.0908):  31%|███       | 12/39 [00:00<00:00, 44.95it/s] \n",
      "Validation: (loss 0.0969):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss 0.0304):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss 0.0046):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss 0.6212):  31%|███       | 12/39 [00:00<00:00, 44.95it/s]\n",
      "Validation: (loss 0.6212):  51%|█████▏    | 20/39 [00:00<00:00, 56.04it/s]\n",
      "Validation: (loss 0.1431):  51%|█████▏    | 20/39 [00:00<00:00, 56.04it/s]\n",
      "Validation: (loss 0.0959):  51%|█████▏    | 20/39 [00:00<00:00, 56.04it/s]\n",
      "Validation: (loss 0.0069):  51%|█████▏    | 20/39 [00:00<00:00, 56.04it/s]\n",
      "Validation: (loss 0.0463):  51%|█████▏    | 20/39 [00:00<00:00, 56.04it/s]\n",
      "Validation: (loss 0.0173):  51%|█████▏    | 20/39 [00:00<00:00, 56.04it/s]\n",
      "Validation: (loss 0.5909):  51%|█████▏    | 20/39 [00:00<00:00, 56.04it/s]\n",
      "Validation: (loss 0.5909):  67%|██████▋   | 26/39 [00:00<00:00, 57.32it/s]\n",
      "Validation: (loss 0.2383):  67%|██████▋   | 26/39 [00:00<00:00, 57.32it/s]\n",
      "Validation: (loss 0.1214):  67%|██████▋   | 26/39 [00:00<00:00, 57.32it/s]\n",
      "Validation: (loss 0.2124):  67%|██████▋   | 26/39 [00:00<00:00, 57.32it/s]\n",
      "Validation: (loss 0.0488):  67%|██████▋   | 26/39 [00:00<00:00, 57.32it/s]\n",
      "Validation: (loss 0.0929):  67%|██████▋   | 26/39 [00:00<00:00, 57.32it/s]\n",
      "Validation: (loss 0.7133):  67%|██████▋   | 26/39 [00:00<00:00, 57.32it/s]\n",
      "Validation: (loss 0.7133):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.0639):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.0712):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.0431):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.0043):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.0883):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.5467):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.0168):  82%|████████▏ | 32/39 [00:00<00:00, 57.89it/s]\n",
      "Validation: (loss 0.0168): 100%|██████████| 39/39 [00:00<00:00, 60.87it/s]\n",
      "Progress: 100%|██████████| 2/2 [00:35<00:00, 17.86s/it]                   \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg validation loss: 0.16829593632465753\n",
      "Saved model unet3d_fullblob0302_1029.pt\n",
      "Using unet3d\n",
      "Predicting segmentation on volume of shape (128, 390, 385)\n",
      "Loaded model from /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/fcn/03022023_10_28_24_trained_fcn_model/unet3d_fullblob0302_1029.pt\n",
      "(128, 390, 385)\n",
      "Predict and aggregate on volume of torch.Size([1, 128, 390, 385])\n",
      "  0%|          | 0/192 [00:00<?, ?it/s]\n",
      "Aggregated volume of torch.Size([1, 128, 390, 385])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - Launching (pass_through::float64)  - survos2.improc.utils:map_blocks:485\n",
      "INFO - Applying <function pass_through at 0x7ff0af9109d0> to datasets of shape [dask.array<array, shape=(128, 390, 385), dtype=float64, chunksize=(128, 78, 129), chunktype=numpy.ndarray>] with stack: False  - survos2.improc.utils:_apply:334\n",
      "WARNING - Performing automatic data casting from 'float64' to 'float32'  - survos2.model.dataset:set_data:399\n",
      "INFO - Creating dataset on /ceph/users/fot15858/chroot/vf_main2_sept11_roi_0_128_308_698_338_723/default/features/002_logit_map [128, 390, 385] float32 None [128, 195, 97]  - survos2.model.dataset:create:241\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting key value workspace, vf_main2_sept11_roi_0_128_308_698_338_723\n",
      "Setting key value anno_id, 003_level\n",
      "Setting key value feature_id, 001_raw\n",
      "Setting key value objects_id, 001_points\n",
      "Setting key value num_samples, 200\n",
      "Setting key value num_epochs, 2\n",
      "Setting key value num_augs, 1\n",
      "Setting key value patch_size, [64, 64, 64]\n",
      "Setting key value patch_overlap, [16, 16, 16]\n",
      "Setting key value fcn_type, unet3d\n",
      "Setting key value bce_to_dice_weight, 0.7\n",
      "Setting key value threshold, 0.5\n",
      "INFO:     127.0.0.1:41204 - \"GET /pipelines/train_3d_cnn?src=survos%3A%2F%2Fdefault%40vf_main2_sept11_roi_0_128_308_698_338_723%3Apipelines%2F022_train_3d_cnn&dst=survos%3A%2F%2Fdefault%40vf_main2_sept11_roi_0_128_308_698_338_723%3Apipelines%2F022_train_3d_cnn&anno_id=003_level&feature_id=001_raw&objects_id=001_points&kind=train_3d_cnn&source=001_raw&id=022_train_3d_cnn&num_samples=200&num_epochs=2&num_augs=1&patch_size=64&patch_size=64&patch_size=64&patch_overlap=16&patch_overlap=16&patch_overlap=16&fcn_type=unet3d&bce_to_dice_weight=0.7&threshold=0.5&workspace=vf_main2_sept11_roi_0_128_308_698_338_723 HTTP/1.1\" 200 OK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - + Computed: train_3d_cnn  - survos2.api.utils:wrapper:83\n"
     ]
    }
   ],
   "source": [
    "for method in ['U_NET_PLUS_PLUS',]: #['U_NET','DEEPLABV3', 'U_NET_PLUS_PLUS', 'FPN', 'MA_NET']:\n",
    "    logger.info('Running notebook for: {}'.format(method))\n",
    "    pm.execute_notebook(input_path='Seg_Basic_Multiaxis.ipynb', \n",
    "                        output_path='artifact_dir/notebooks/basic_{}.ipynb'.format(method),\n",
    "                        parameters={'workspace_name': 'vf_main2_sept11_roi_0_128_308_698_338_723', \n",
    "                                    'port':port, \n",
    "                                    'method':method,\n",
    "                                    'loss_criterion':loss_criterion,\n",
    "                                    'encoder_type':encoder_type})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55339000-4132-4bea-a8d1-993650116f44",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd76794-57d6-4bf1-9c27-46895d853739",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4514fb-c26e-431b-bf0d-1a8c1e8dbcf7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d9cc45-04f3-41e6-a188-8803a3d74dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#stop_server(server_process)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
